var documenterSearchIndex = {"docs":
[{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"One-to-One Target–Decoy Pairing With Decoy Cloning","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Goal","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Guarantee that every pairid identifies exactly one target and one decoy across PSMs, even when multiple targets map to a single decoy. Avoid unintended “target A vs target B” grouping in later stages (e.g., summarizeprecursors!, applymbrfilter!). Persist pair_id to PSM files so MBR filtering operates on correct 1:1 pairs.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Problems To Solve","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Many-to-one: Multiple targets (A, B, …) may need the same decoy C. If all rows A, B, C share the same pair_id, the “pair” can accidentally include A–B together.\nDownstream grouping: summarizeprecursors! and applymbrfilter! group by pairid. If pair_id is not 1:1, we get incorrect within-run comparisons and false transfers.\nTraining leakage: Cloned decoy rows should not distort training distributions, but they must exist later for correct pairing and MBR grouping.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Design Overview","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Decoy cloning: For each additional target that is assigned to decoy C beyond the first, create a cloned decoy row (same chromatogram features) and assign a new unique pairid for the target–clone pair. The original decoy keeps a distinct pairid with its first target.\n1:1 invariant: After cloning, each pair_id appears in exactly two roles: one target and one decoy (canonical or clone).\nExclude clones from training: Cloned decoy rows are not used when fitting models but must be present for inference and written out to per-run PSM files after scoring.\nStratified pairing: Create target–decoy assignments within 10×10 bins in (prec_mz × iRT) to preserve similarity of pairs. Use global fallback bins when strata are sparse.\nDeterministic: Use a fixed RNG seed for reproducibility.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Data Model Additions","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"New columns on the PSM DataFrame (in-memory only; all exported to files except those marked ephemeral):\n:pair_id::UInt32 – unique 1:1 identifier for target–decoy pairs (persisted to Arrow files).\n:pair_role::UInt8 – 0=target, 1=decoy (canonical), 2=decoy_clone (optional; can derive from :target and clone flag).\n:pair_clone_of::Union{Missing,UInt32} – precursor_idx of the canonical decoy for clones; missing for targets and canonical decoys.\n:pair_training_mask::Bool – false for clones to exclude them from training sets (ephemeral).","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Where To Implement","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"File: src/utils/ML/percolatorSortOf.jl\nFunction entry: sort_of_percolator_in_memory!\nTiming: Very start, before sort!(psms, [:pair_id, :isotopes_captured])","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Algorithm (Pair Generation)","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Build precursor-level table","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Collapse PSMs to unique precursor_idx, keeping first target::Bool, prec_mz::Float32, and iRT column. iRT precedence: :irt_pred > :irt_obs; if both missing, use a single iRT bin.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Create 10×10 bins (prec_mz × iRT)","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Compute quantile-based edges for prec_mz and chosen iRT (0:0.1:1.0). Deduplicate and enforce strictly increasing edges; otherwise fallback to even-width LinRange(min,max,11).\nAssign each precursor to a (binmz, binirt) stratum via searchsortedlast and clamp to [1,10]. If iRT missing, use 10×1 bins.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Stratified target–decoy assignment per stratum","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"For each stratum s:\ntargets_s = shuffle(target precursors in s)\ndecoys_s = shuffle(decoy precursors in s)\nIf one side is empty locally, use a globally-shuffled pool from the full dataset for that side.\nDetermine which side is smaller:\nIf length(decoys_s) < length(targets_s): assign each decoy to multiple targets (decoy-reuse). Maintain mapping assignments_decoy[d] => Vector{targets}.\nIf length(targets_s) < length(decoys_s): assign each target to multiple decoys (target-reuse). Maintain mapping assignments_target[t] => Vector{decoys}.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Construct pair_id and clones (no-unpaired invariant)","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"We ensure every precursor participates in a 1:1 pair_id unless one side is truly absent (no targets or no decoys even after global fallback). Choose cloning based on which side is larger in the stratum:\nDecoys fewer than targets (decoy-reuse): For each decoy d with assigned targets [t1, t2, …]:\nFirst target t1: pair_id = next_id(); assign to t1 and canonical d.\nEach additional target ti (i ≥ 2): clone d’s PSM rows per run; set pair_id = next_id(), pair_clone_of = d, pair_training_mask = false.\nTargets fewer than decoys (target-reuse): For each target t with assigned decoys [d1, d2, …]:\nFirst decoy d1: pair_id = next_id(); assign to canonical t and d1.\nEach additional decoy dj (j ≥ 2): clone t’s PSM rows per run; set pair_id = next_id(), pair_clone_of = t, pair_training_mask = false.\nCanonical (non-clone) rows always have pair_training_mask = true.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Update the full PSM DataFrame","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Overwrite/create :pair_id with the newly assigned values for all rows (canonical + clones + targets).\nAdd :pair_clone_of and :pair_training_mask as above.\nPreserve original ordering, or re-sort by [:pair_id, :isotopes_captured] as today.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Training, Prediction, and Write-Back","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Exclude clones when selecting training rows","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"In get_training_data_for_iteration!, filter by pair_training_mask (keep true rows only). This avoids inflating decoy counts.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Inference on clones","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Keep clones in the test/inference set (fold assignment unchanged). They receive model probabilities directly. Alternatively (optimization), copy predictions from their canonical decoy; initially, compute directly for simplicity and correctness.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Persist to Arrow files","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"write_scored_psms_to_files! writes out the PSMs including the cloned decoy rows and the regenerated pair_id. Keep :pair_id and drop only vector columns as before.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Downstream Changes","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"applymbrfilter! requires :pair_id","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Remove the fallback that re-derives pair_id from the library.\nIf :pair_id is missing in mergeddf, throw an error with a clear message: the file must be produced by the new pipeline that regenerates pairid.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"summarize_precursors! grouping remains the same","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"With 1:1 pair_id, within-run target–decoy logic is correct. No further changes required aside from previously added robustness to use :mbr_prob or :prob.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"applymbrfilter! adjustments (with 1:1 pair_id)","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Preconditions:\nmergeddf contains `:pairid::UInt32,:prob::Float32,:target::Bool,:decoy::Bool,:MBRtransfercandidate::Bool, and:msfileidx`.\nEach :pair_id denotes exactly one target and one decoy per run (thanks to cloning during pairing).\nRemove library-derived pair_id code:\nDelete any attempt to recompute :pair_id from the spectral library (e.g., via getPairId).\nInsert a hard check: if :pair_id ∉ propertynames(mergeddf) → `error(\"pairid missing; regenerate pairs before ScoringSearch\")`.\nCandidate set and non-candidates:\ncandidate_mask = merged_df.MBR_transfer_candidate.\nCompute trace q-values only on non-candidates with library FDR scaling for diagnostics: get_qvalues!(merged_df.prob[.!candidate_mask], merged_df.target[.!candidate_mask], trace_qval[.!candidate_mask]).\nWithin-run target–decoy dominance:\nGroup candidates by [:ms_file_idx, :pair_id].\nFor each group, identify best target and best decoy (there should be at most one of each). If either is missing, skip the group with a warning counter.\nIf best_decoy_prob ≥ best_target_prob, mark the target row in this group as a transfer decoy (bad). Always mark decoy rows as transfer decoys, since they are the reference negatives.\nBuild bad-mask and threshold:\nbad_mask = candidate_mask .& (merged_df.decoy .| target_marked_as_bad).\nCompute τ with get_ftr_threshold(merged_df.prob, merged_df.target, bad_mask, α; mask=candidate_mask), where α = params.max_MBR_false_transfer_rate (or α' if alpha-scaling experiment is enabled).\nClamp candidate probabilities:\nmerged_df._filtered_prob = ifelse.(candidate_mask .& (merged_df.prob .< τ), 0f0, merged_df.prob) and return :_filtered_prob.\nLogging and diagnostics:\nCount candidate groups lacking a target or decoy; log as potential data issues.\nLog (α, τ, #candidates, #transfer_decoys) and a small sample of group-level decisions for QA.\nInteraction with stratified FTR experiments:\nIf later stratifying FTR calibration, reuse :pair_id structure but compute τ within strata (e.g., by MBR_num_runs or donor-count), applying the above dominance rule inside each stratum.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Validation & Diagnostics","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Before/after stats:\nUnique pair_id count; distribution of group sizes (expect mostly 2, some 1).\nFraction of decoys cloned (and average clone count).\nPer-stratum pairing coverage; number of strata using global fallback.\nCorrectness checks:\nFor each pair_id, ensure at most one target and at most one decoy row per run.\nOn a small dataset, assert the 1:1 property holds globally.\nLogging:\nSeed, bins used, stratum sizes, counts of clones, any fallbacks triggered.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Performance Considerations","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Cloning increases row count by up to the number of extra target assignments per decoy. In typical DIA datasets, this should be a moderate multiplier. Monitor memory and optionally gate on dataset size.\nIf needed later, add a config toggle to disable cloning (fallback to original behavior) for memory-constrained runs.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Rollout Steps & Commits","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Commit checkpoint (baseline):","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Commit current state before changes as chore(MBR): checkpoint before 1:1 pairing work.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Implement pairing + cloning + training mask + persistence","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Add regenerate_pair_ids! helper and call at top of sort_of_percolator_in_memory!.\nModify get_training_data_for_iteration! to respect pair_training_mask.\nEnsure write_scored_psms_to_files! persists :pair_id (and optionally :pair_clone_of for debugging).","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Update applymbrfilter!","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Remove library-derived pair_id fallback.\nError if :pair_id missing in merged_df.","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Commit implementation:","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"feat(MBR): 1:1 target–decoy pairing with decoy cloning and persisted pair_id","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Verification run","category":"page"},{"location":"advanced/mbr_pairing_strategy/","page":"-","title":"-","text":"Run a representative dataset; check logs and pairing stats; verify applymbrfilter! sees pair_id and completes.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Simpler Pairing Strategy — Critique And Alternative Plan","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"This document proposes a simpler approach to pairing for MBR that achieves the same downstream effect without cloning rows or regenerating pair_id at scoring time. It also critiques the prior “simple” pairing plan (not in repo here) that introduced additional complexity.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Critique Of The Prior Plan","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Complexity and memory cost: Cloning decoy (or target) rows to enforce 1:1 pair_id multiplies the PSM table size and introduces quadratic‑like costs if clones are appended iteratively.\nMoving targets: Re‑pairing at scoring time overrides a stable library invariant. The spectral library already encodes target/decoy pairing (e.g., pair_id) upstream; redefining pairs late in the pipeline makes debugging harder and risks drift between runs.\nCoupling to downstream logic: Enforcing 1:1 at the row level only to satisfy a specific grouping in apply_mbr_filter! creates tight coupling. A better approach is to compute dominance flags directly and keep apply_mbr_filter! agnostic to strict 1:1 groups.\nCV‑fold nuances: Pairing within cv_fold and bins is brittle. The scorer already computes robust MBR features per run; the pairing step is redundant if we express “decoy outranks target” with per‑row flags.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Goal","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Preserve the practical outcome (flag and control risky transfers) without cloning or regenerating pair_id.\nReduce CPU/memory use, avoid write‑amplification, and keep the data model stable.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Key Observation","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"The MBR filter does not inherently require 1:1 pair groups if we provide per‑row dominance flags. Earlier we already compute:\nMBR_max_pair_prob and MBR_is_best_decoy in summarize_precursors!.\nA candidate mask in the scorer.\napply_mbr_filter! can operate on those signals without grouping.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Proposed Simpler Design","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Do not regenerate pair_id at scoring time","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Keep the library’s pair_id (if present) as a passive attribute. Don’t modify it or rely on it for strict 1:1.\nIf pair_id is missing in some PSMs, that’s okay — the steps below don’t depend on it.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Fix candidate labeling in the in‑memory scorer","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"File: src/utils/ML/percolatorSortOf.jl\nFunction: sort_of_percolator_in_memory!\nReplace the probability‑based pass mask with q‑value based logic (mirroring update_mbr_probs!):","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"qvals_prev = similar(nonMBR_estimates)\nget_qvalues!(nonMBR_estimates, psms.target, qvals_prev)\npass_mask = (qvals_prev .<= max_q_value_lightgbm_rescore) .& psms.target\nprob_thresh = any(pass_mask) ? minimum(nonMBR_estimates[pass_mask]) : typemax(Float32)\npsms[!, :MBR_transfer_candidate] .= (qvals_prev .> max_q_value_lightgbm_rescore) .&\n                                    (psms.MBR_max_pair_prob .>= prob_thresh)","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Compute per‑row dominance without cloning","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"summarize_precursors! already determines, per run, a “best other run” via MBR_max_pair_prob and flags MBR_is_best_decoy.\nIf we want a single, direct dominance flag for filtering, compute it after final probabilities with a single grouped combine over candidates only (no cloning, no pair regeneration):","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"agg = combine(groupby(view(psms, psms.MBR_transfer_candidate, :),\n                      [:ms_file_idx, :pair_id, :target]),\n              :prob => maximum => :max_prob)\ntgt = rename!(agg[agg.target .== true, [:ms_file_idx, :pair_id, :max_prob]], :max_prob => :tmax)\ndcy = rename!(agg[agg.target .== false, [:ms_file_idx, :pair_id, :max_prob]], :max_prob => :dmax)\npairmax = outerjoin(tgt, dcy, on=[:ms_file_idx, :pair_id])\npairmax[!, :MBR_paired_decoy_higher] = coalesce.(pairmax.dmax, -Inf32) .> coalesce.(pairmax.tmax, -Inf32)\npsms = leftjoin(psms, pairmax[:, [:ms_file_idx, :pair_id, :MBR_paired_decoy_higher]], on=[:ms_file_idx, :pair_id])\npsms[!, :MBR_paired_decoy_higher] = ifelse.(psms.target, coalesce.(psms.MBR_paired_decoy_higher, false), false)","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Notes:","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"This is optional if MBR_is_best_decoy is already reliable for filtering.\nIt avoids cloning and only touches the minimal set of rows.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Keep apply_mbr_filter! simple","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"File: src/Routines/SearchDIA/SearchMethods/ScoringSearch/scoring_interface.jl\nFunction: apply_mbr_filter!\nUse the candidate mask and a simple bad‑transfer predicate (original form):","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"candidate_mask = merged_df.MBR_transfer_candidate\nis_bad_transfer = candidate_mask .& (\n    (merged_df.target .& coalesce.(merged_df.MBR_is_best_decoy, false)) .|\n    merged_df.decoy\n)\nτ = get_ftr_threshold(merged_df.prob, merged_df.target,\n                      is_bad_transfer, params.max_MBR_false_transfer_rate;\n                      mask=candidate_mask)\nmerged_df._filtered_prob = ifelse.(candidate_mask .& (merged_df.prob .< τ), 0f0, merged_df.prob)","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"This design works whether pair_id exists or not and does not require strict 1:1 pairing.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Benefits","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"No cloning or re‑pairing: Lower memory/CPU, simpler control flow, smaller risk of regression.\nStable semantics: Relies on per‑row flags and q‑value logic already present.\nDecoupled filter: apply_mbr_filter! needs only a candidate mask and a bad‑transfer mask — no grouping gymnastics.","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Implementation Notes","category":"page"},{"location":"advanced/simple_pairing_plan_alt/","page":"-","title":"-","text":"Instrumentation: Log candidate counts and prob_thresh after labeling to confirm realistic set sizes.\nOut‑of‑memory parity: The OOM path already uses correct q‑value‑based labeling (update_mbr_probs!). With this plan, both paths are aligned semantically.","category":"page"},{"location":"supplemental_methods/CLAUDE/#Supplemental-Methods-Documentation","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/#Overview","page":"Supplemental Methods Documentation","title":"Overview","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"all_methods.tex is a comprehensive LaTeX draft of supplemental methods for a manuscript describing Pioneer and Altimeter, a DIA (Data-Independent Acquisition) proteomics analysis software suite optimized for narrow isolation windows.","category":"page"},{"location":"supplemental_methods/CLAUDE/#Document-Structure","page":"Supplemental Methods Documentation","title":"Document Structure","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"The document is formatted for Nature journal submission (sn-nature document class) with ~1079 lines and includes detailed mathematical formulations for all algorithms.","category":"page"},{"location":"supplemental_methods/CLAUDE/#Main-Sections","page":"Supplemental Methods Documentation","title":"Main Sections","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Altimeter Training Data & Model (Lines 51-149)\nTraining dataset from ProteomeTools project (PRIDE archives)\nDatabase searching with sage v0.14.7\nSpectrum filtering and quality control\nFragment ion annotation and deisotoping\nNCE (normalized collision energy) alignment\nTransformer-based model architecture (11.8M parameters)\nCubic B-spline coefficients for fragment intensity prediction\nKoina framework deployment with 4 inference variants\nPioneer - File Conversion (Lines 168-170)\nCross-platform MS file conversion to Apache Arrow IPC format\nSupports Thermo .raw and .mzML files\nPioneerConverter tool (GitHub: nwamsley1/PioneerConverter)\nSpectral Library Generation (Lines 175-184)\nFASTA protein sequence digestion\nTarget-decoy sequence generation (reverse/shuffle)\nEntrapment sequence integration for FDR calibration\nProtein group definition (mathematical formulation)\nIntensity-Aware Fragment Index Search (Lines 188-283)\nModified fragment-index algorithm accounting for library intensities\nHierarchical bin structure (retention time → fragment m/z)\nScore counter data structure\nBinary search-based MS/MS scan queries\nParameter Tuning (Lines 293-381)\nPre-search for run-specific parameter estimation\nRetention time alignment via B-splines\nMass error/tolerance estimation (exponential distributions)\nNCE alignment with piecewise linear model\nFirst Pass Search (Lines 386-526)\nIterative training procedure based on Percolator\nProbit regression model for PSM scoring\nPEP (Posterior Error Probability) estimation via wPAVA\nPSM aggregation across runs\nRefined RT alignment and tolerance estimation\nSpectral Deconvolution (Lines 534-598)\nMatrix representation of library/empirical spectra\nSparse column-major layout for efficiency\nPseudo-Huber loss minimization with non-negativity constraints\nCoordinate descent optimization with Newton-Raphson solver\nHot-start initialization\nTarget-Decoy Model & Match-Between-Runs (Lines 602-860)\nLightGBM models with cross-validation\nIterative training with negative mining\nMBR (Match-Between-Runs) features:\nRV coefficient for chromatographic similarity\nRetention time differences\nIntensity ratios\nCross-run evidence\nFalse Transfer Rate (FTR) filtering\nTwo-stage FDR control (global + experiment-wide q-values)\nProbability aggregation (trace → precursor-run → global)\nChromatogram Quantification (Lines 864-906)\nWhittaker-Henderson smoothing\nApex refinement\nPeak boundary detection via second derivative\nBaseline subtraction\nTrapezoidal integration\nProtein Inference & Quantification (Lines 911-1067)\nParsimony-based inference algorithm\nTwo-phase approach: unique peptides → greedy set cover\nBipartite graph decomposition via DFS\nLightGBM-based protein scoring (optional)\nMaxLFQ algorithm for label-free quantification\nFragment Isotope Correction (Lines 1073-end)\nConditional fragment isotope probabilities\nQuadrupole-filtered precursor isotope distribution\nRe-isotoping of library spectra","category":"page"},{"location":"supplemental_methods/CLAUDE/#Key-Features","page":"Supplemental Methods Documentation","title":"Key Features","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/#Mathematical-Rigor","page":"Supplemental Methods Documentation","title":"Mathematical Rigor","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Formal definitions using set notation\nDetailed algorithm pseudocode (e.g., protein inference algorithm)\nLoss functions, optimization objectives clearly stated\nStatistical models (probit regression, isotonic regression, exponential fits)","category":"page"},{"location":"supplemental_methods/CLAUDE/#Cross-References-to-Code","page":"Supplemental Methods Documentation","title":"Cross-References to Code","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"The document is designed to map to the Julia implementation in Pioneer.jl. Line numbers in the protein inference algorithm (lines 117-380) appear to reference actual source code.","category":"page"},{"location":"supplemental_methods/CLAUDE/#FDR-Control-Strategy","page":"Supplemental Methods Documentation","title":"FDR Control Strategy","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Multi-layered approach:","category":"page"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Spectrum-level (Sage searches)\nPSM-level (Percolator-style iterative training)\nPrecursor-level (two-stage global + experiment-wide)\nProtein-level (target-decoy competition)\nTransfer-level (FTR for match-between-runs)","category":"page"},{"location":"supplemental_methods/CLAUDE/#Novel-Contributions","page":"Supplemental Methods Documentation","title":"Novel Contributions","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Intensity-aware fragment indexing - accounts for predicted intensities in scoring\nNCE alignment - maps vendor collision energies to PROCAL Lumos scale\nConditional fragment isotopes - models isotopes based on quadrupole transmission\nFTR filtering - controls false transfers in match-between-runs\nIntegrated workflow - spectral prediction (Altimeter) → search → quantification (Pioneer)","category":"page"},{"location":"supplemental_methods/CLAUDE/#Technical-Details","page":"Supplemental Methods Documentation","title":"Technical Details","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/#Authors","page":"Supplemental Methods Documentation","title":"Authors","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Nathan T. Wamsley (lead)\nEmily M. Wilkerson\nBen Major\nDennis Goldfarb (corresponding)","category":"page"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Washington University School of Medicine","category":"page"},{"location":"supplemental_methods/CLAUDE/#Software-Stack","page":"Supplemental Methods Documentation","title":"Software Stack","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Altimeter: PyTorch transformer model (UniSpec architecture)\nPioneer: Julia implementation\nSearch: Sage v0.14.7\nML Models: LightGBM, probit regression\nQuantification: MaxLFQ\nFile I/O: Apache Arrow IPC format","category":"page"},{"location":"supplemental_methods/CLAUDE/#Data-Sources","page":"Supplemental Methods Documentation","title":"Data Sources","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"ProteomeTools PRIDE datasets: PXD021013, PXD010595, PXD004732, PXD006832\nUniProt human reference proteome (2024-06-04)","category":"page"},{"location":"supplemental_methods/CLAUDE/#Implementation-Notes","page":"Supplemental Methods Documentation","title":"Implementation Notes","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"When working with Pioneer.jl code:","category":"page"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Protein inference logic is in src/utils/proteinInference.jl\nLine numbers in the algorithm pseudocode (lines 117-380) map to source\nThe two-phase approach (unique peptides first, then greedy set cover) is the core logic\nConnected components are discovered via DFS before inference\nQuantification flags (use_for_quant) distinguish unique vs. shared peptides","category":"page"},{"location":"supplemental_methods/CLAUDE/#Document-Status","page":"Supplemental Methods Documentation","title":"Document Status","text":"","category":"section"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"DRAFT - This is supplemental methods for an in-preparation manuscript. Expect:","category":"page"},{"location":"supplemental_methods/CLAUDE/","page":"Supplemental Methods Documentation","title":"Supplemental Methods Documentation","text":"Missing cross-references (marked with \\ref{REFHERE}, \\ref{ref here})\nPlaceholder citations (e.g., \"LightGBM paper...\")\nTODO markers in red text (e.g., \\textcolor{red}{...})\nPotential formatting/equation adjustments before submission","category":"page"},{"location":"api/core/#api-reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"user_guide/parameters/#Parameter-Configuration","page":"Parameter Configuration","title":"Parameter Configuration","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Pioneer uses JSON configuration files to control analysis. This guide explains the parameters for both SearchDIA and BuildSpecLib.","category":"page"},{"location":"user_guide/parameters/#SearchDIA-Configuration","page":"Parameter Configuration","title":"SearchDIA Configuration","text":"","category":"section"},{"location":"user_guide/parameters/#Frequently-Modified-Parameters","page":"Parameter Configuration","title":"Frequently Modified Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Most parameters should not be changed, but the following may need adjustment.","category":"page"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"first_search.fragment_settings.min_score: The minimum score determines which fragments must match in the fragment-index search in order for the precursor to pass. Each precursor is awarded a score based on which fragments match the spectrum. The score assigned to each fragment depends on its intensity rank. The default scheme is 8,4,4,2,2,1,1. That is, if the 1st, 3rd, and 7th ranking fragments matched the spectrum, the precursor would be awarded a score of 8+4+1=13. If all 7 of the fragments matched, the precursor would be awarded a score of 22. For normal instrument settings on an Orbitrap or Astral mass analyzer, the mass tolerance is about +/- 5-15 ppm and 15 is a reasonable default score threshold. However, for instruments with less mass accuracy (Sciex ZenoTOF 7600 or different Orbitrap scan settings), the score threshold may need to be set higher, perhaps to 20. It may be worthwhile to test different values when searching data from a new instrument or sample type. In order to pass the first search, a precursor need only pass the threshold and score sufficiently well in at least one of the MS data files.\nfirst_search.fragment_settings.max_rank: Search against only the n'th most abundant fragment for each precursor. Including more fragments can improve performance but increase memory consumption, and the search could take longer. From experience, there are diminishing returns after 25-50 fragments.\nquant_search.fragment_settings.max_rank: See above\nquant_search.fragment_settings.n_isotopes: If searching with non-Altimeter libraries (not recommended), such as Prosit or UniSpec, this should be set to 1 as the second fragment isotopes will not be calculated accurately.\nacquisition.nce: This is the initial guess for the normalized collision energy that will best align the Altimeter Library with the empirical data. Altimeter values should agree with those from Thermo Instruments manufactured in Bremen Germany. If upon inspection of the quality control plots the initial guess is far from the estimated value, it might be possible to improve search results slightly by re-searching with a better initial guess.\nacquisition.quad_transmission.fit_from_data: Estimate the quad transmission function from the data. Otherwise defaults to symmetric, smooth function.\noptimization.machine_learning.max_psms_in_memory: This is the maximum number of PSMs to hold in memory for LightGBM training. These PSMs need to comfortably fit in memory in addition to the spectral library. As a rule of thumb, 7M rows is about 1GB. At the default maximum of 50M rows, the PSMs table will consume about 7GB of memory.\nDuring LightGBM training, any missing feature values are replaced with the column median. If a column is entirely missing, the values are filled with zero of the appropriate type.","category":"page"},{"location":"user_guide/parameters/#Global-Parameters","page":"Parameter Configuration","title":"Global Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nisotope_settings.err_bounds_first_pass [Int, Int] Precursor monoisotope may lie NEUTRON/charge Thompsons (left, right) outside the quadrupole isolation window (default: [1, 0])\nisotope_settings.err_bounds_quant_search [Int, Int] Precursor monoisotope may lie NEUTRON/charge Thompsons (left, right) outside the quadrupole isolation window (default: [3, 0])\nisotope_settings.combine_traces Boolean Whether to combine precursor isotope traces in quantification (default: true)\nisotope_settings.partial_capture Boolean Whether to estimate the conditional fragment isotope distribution (true) or assume complete transmission of the entire precursor isotopic envelope (default: true)\nisotope_settings.min_fraction_transmitted Float Minimum fraction of the precursor isotope distribution that must be isolated for scoring and quantitation (default: 0.25)\nscoring.q_value_threshold Float Global q-value threshold for filtering results. Also controls false transfer rate of MBR (default: 0.01)\nnormalization.n_rt_bins Int Number of retention time bins for quant normalization (default: 100)\nnormalization.spline_n_knots Int Number of knots in quant normalization spline (default: 7)\nhuber_override.override_huber_delta_fit Boolean Whether to override the automatic Huber delta fitting with a manual value (default: false)\nhuber_override.huber_delta Float Huber delta value when override is enabled (default: 1055)\nms1_scoring Boolean Enable MS1-level scoring features (default: true)\nms1_quant Boolean Enable MS1-level quantification (default: false)\nmatch_between_runs Boolean Whether to attempt to transfer peptide identifications across runs. Turning this on will add additional features to the LightGBM model (default: true)","category":"page"},{"location":"user_guide/parameters/#Parameter-Tuning-Settings","page":"Parameter Configuration","title":"Parameter Tuning Settings","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nfragment_settings.min_count Int Minimum number of matching fragment ions (default: 7)\nfragment_settings.max_rank Int Maximum rank of fragments to consider (default: 25, means 26th-last most abundant fragments per precursor are filtered out)\nfragment_settings.min_score [Int, Int] Minimum fragment-index score thresholds (default: [22, 17])\nfragment_settings.min_spectral_contrast Float Minimum cosine similarity score (default: 0.5)\nfragment_settings.relative_improvement_threshold Float Minimum relative Scribe score improvement needed to ignore an interfering peak (default: 1.25)\nfragment_settings.min_log2_ratio Float Minimum log2 ratio of matched library fragment intensities to unmatched library fragment intensities (default: 1.5)\nfragment_settings.min_top_n [Int, Int] Minimum number of top N matches - [requirement, denominator]. Default: [3, 3]\nfragment_settings.n_isotopes Int Number of fragment isotopes to consider in matching (default: 1, mono only)\nfragment_settings.intensity_filter_quantile Float Quantile for intensity-based fragment filtering (default: 0.50)\nsearch_settings.min_samples Int Minimum number of PSMs required for tuning (default: 1200)\nsearch_settings.max_presearch_iters Int Maximum number of parameter tuning iterations (default: 10)\nsearch_settings.frag_err_quantile Float Quantile for fragment error estimation (default: 0.005)\nsearch_settings.max_q_value Float Maximum q-value for parameter tuning PSMs (default: 0.01)\nsearch_settings.topn_peaks Int Top N peaks per spectrum to consider (default: 200)\nsearch_settings.max_frags_for_mass_err_estimation Int Maximum fragments used for mass error model (default: 12)\nnce_tuning.min_psms Int Minimum PSMs for NCE tuning (default: 2000)\nnce_tuning.initial_percent Float Initial sampling percentage for NCE tuning (default: 2.5)\nnce_tuning.min_initial_scans Int Minimum initial scans for NCE tuning (default: 5000)\nquad_tuning.min_psms_per_thompson Int Minimum PSMs per Thompson width for quad transmission tuning (default: 250)\nquad_tuning.min_fragments Int Minimum fragments per PSM for quad tuning (default: 3)\nquad_tuning.initial_percent Float Initial sampling percentage for quad tuning (default: 2.5)\niteration_settings.init_mass_tol_ppm [Float, Float] Initial fragment mass tolerance guesses in ppm (default: [20.0, 30.0])\niteration_settings.ms1_tol_ppm Float Initial MS1 mass tolerance in ppm (default: 20.0)\niteration_settings.scan_counts [Int] Scan counts to sample during parameter tuning (default: [10000])","category":"page"},{"location":"user_guide/parameters/#First-Search-Parameters","page":"Parameter Configuration","title":"First Search Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nfragment_settings.min_count Int Minimum number of matching fragments (default: 4)\nfragment_settings.max_rank Int Maximum fragment rank to consider (default: 25)\nfragment_settings.min_score Int Minimum score for fragment matches (default: 15)\nfragment_settings.min_spectral_contrast Float Minimum cosine similarity required (default: 0.5)\nfragment_settings.relative_improvement_threshold Float Minimum relative Scribe score improvement needed to ignore an interfering peak (default: 1.25)\nfragment_settings.min_log2_ratio Float Minimum log2 ratio of matched library fragment intensities to unmatched library fragment intensities (default: 0.0, means sum of matched library fragment intensities is equal to the sum of unmatched library fragment intensities for the precursor)\nfragment_settings.min_top_n [Int, Int] Minimum top N matches - [requirement, denominator]. Default: [2, 3]\nfragment_settings.n_isotopes Int Number of isotopes to consider (default: 1)\nscoring_settings.n_train_rounds Int Number of training rounds for scoring model (default: 2)\nscoring_settings.max_iterations Int Maximum iterations for scoring optimization (default: 20)\nscoring_settings.max_q_value_probit_rescore Float Maximum q-value threshold for semi-supervised learning during probit regression (default: 0.05)\nscoring_settings.max_PEP Float Maximum local FDR threshold for passing the first search (default: 0.9)\nirt_mapping.max_prob_to_impute_irt Float If probability of the PSM is less than x in the first-pass search, then impute iRT for the precursor with globally determined value from the other runs (default: 0.75)\nirt_mapping.fwhm_nstd Float Number of standard deviations of the FWHM to add to the retention time tolerance (default: 4)\nirt_mapping.irt_nstd Int Number of standard deviations of run-to-run iRT tolerance to add to the retention time tolerance (default: 4)\nirt_mapping.plot_rt_alignment Boolean Whether to generate RT alignment diagnostic plots (default: false)","category":"page"},{"location":"user_guide/parameters/#Quantification-Search-Parameters","page":"Parameter Configuration","title":"Quantification Search Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nfragment_settings.min_count Int Minimum fragment count for quantification (default: 3)\nfragment_settings.min_y_count Int Minimum number of y-ions required (default: 2)\nfragment_settings.max_rank Int Maximum fragment rank (default: 255)\nfragment_settings.min_spectral_contrast Float Minimum spectral contrast score (default: 0.0)\nfragment_settings.min_log2_ratio Float Minimum log2 ratio of intensities (default: -1.7)\nfragment_settings.min_top_n [Int, Int] Minimum top N matches - [requirement, denominator]. Default: [2, 3]\nfragment_settings.n_isotopes Int Number of isotopes for quantification (default: 2, include the M1 and M2 isotopes)\nchromatogram.smoothing_strength Float Strength of chromatogram smoothing (default: 1e-6)\nchromatogram.padding Int Number of zeros to pad chromatograms on either side (default: 0)\nchromatogram.max_apex_offset Int Maximum allowed apex offset in #scans where the precursor could have been detected between the second-pass search and re-integration with 1 percent FDR precursors (default: 2)","category":"page"},{"location":"user_guide/parameters/#Acquisition-Parameters","page":"Parameter Configuration","title":"Acquisition Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nnce Int Normalized collision energy initial guess (used in pre-search before NCE tuning) (default: 26)\nquad_transmission.fit_from_data Boolean Whether to fit quadrupole transmission from data (default: true)\nquad_transmission.overhang Float Deprecated (default: 0.25)\nquad_transmission.smoothness Float Smoothness parameter for transmission curve. Higher value means more \"box-like\" shape. (default: 5.0)","category":"page"},{"location":"user_guide/parameters/#RT-Alignment-Parameters","page":"Parameter Configuration","title":"RT Alignment Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nn_bins Int Number of retention time bins for alignment (default: 200)\nbandwidth Float Bandwidth for kernel density estimation (default: 0.25)\nsigma_tolerance Int Number of standard deviations for iRT tolerance after pre-search (default: 4)\nmin_probability Float Minimum probability for alignment PSMs in pre-search (default: 0.95)\nlambda_penalty Float Lambda penalty for spline fitting (default: 0.1)\nransac_threshold_psms Int RANSAC threshold in number of PSMs (default: 500)\nmin_psms_for_spline Int Minimum PSMs required for spline fitting (default: 10)","category":"page"},{"location":"user_guide/parameters/#Optimization-Parameters","page":"Parameter Configuration","title":"Optimization Parameters","text":"","category":"section"},{"location":"user_guide/parameters/#Deconvolution","page":"Parameter Configuration","title":"Deconvolution","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"The deconvolution parameters are split into ms1 and ms2 sub-objects for separate control over MS1 and MS2 deconvolution, plus shared iteration settings.","category":"page"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\ndeconvolution.ms1.lambda Float L2 regularization parameter for MS1 deconvolution (default: 0.0001)\ndeconvolution.ms1.reg_type String Regularization type for MS1: \"none\", \"l1\", or \"l2\" (default: \"l2\")\ndeconvolution.ms1.huber_delta Float Huber delta for MS1 loss function (default: 1e9)\ndeconvolution.ms2.lambda Float L2 regularization parameter for MS2 deconvolution (default: 0.0)\ndeconvolution.ms2.reg_type String Regularization type for MS2: \"none\", \"l1\", or \"l2\" (default: \"none\")\ndeconvolution.ms2.huber_delta Float Huber delta for MS2 loss function (default: 300)\ndeconvolution.huber_exp Float Exponent for Huber delta progression (default: 1.5)\ndeconvolution.huber_iters Int Number of Huber outer iterations (default: 15)\ndeconvolution.newton_iters Int Maximum Newton iterations per outer iteration (default: 50)\ndeconvolution.bisection_iters Int Maximum bisection iterations when Newton fails (default: 100)\ndeconvolution.outer_iters Int Maximum outer iterations for convergence (default: 1000)\ndeconvolution.newton_accuracy Float Absolute convergence threshold for Newton method (default: 10)\ndeconvolution.bisection_accuracy Float Absolute convergence threshold for bisection method (default: 10)\ndeconvolution.max_diff Float Relative convergence threshold - maximum relative change in weights between iterations. Also used as relative tolerance for Newton's method (default: 0.01)","category":"page"},{"location":"user_guide/parameters/#Machine-Learning","page":"Parameter Configuration","title":"Machine Learning","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nmachine_learning.max_psms_in_memory Int Maximum number of PSMs to hold in memory for LightGBM training (default: 50000000)\nmachine_learning.min_trace_prob Float Minimum trace probability threshold (default: 0.75)\nmachine_learning.max_q_value_mbr_itr Float q-value threshold for match-between-runs candidates kept during the iterative training (ITR) stage of LightGBM rescoring (default: 0.20)\nmachine_learning.min_PEP_neg_threshold_itr Float Minimum posterior error probability threshold for reclassifying weak target PSMs as negatives during the ITR stage of LightGBM rescoring (default: 0.90)\nmachine_learning.spline_points Int Number of points for probability spline (default: 500)\nmachine_learning.interpolation_points Int Number of interpolation points (default: 10)\nmachine_learning.n_quantile_bins Int Number of quantile bins for score binning (default: 25)\nmachine_learning.enable_model_comparison Boolean Enable comparison of scoring models (default: true)\nmachine_learning.validation_split_ratio Float Fraction of data held out for validation (default: 0.2)\nmachine_learning.qvalue_threshold Float q-value threshold for model comparison (default: 0.01)\nmachine_learning.min_psms_for_comparison Int Minimum PSMs to enable model comparison (default: 1000)\nmachine_learning.max_psms_for_comparison Int Maximum PSMs for in-memory model comparison (default: 100000)","category":"page"},{"location":"user_guide/parameters/#Protein-Inference-Parameters","page":"Parameter Configuration","title":"Protein Inference Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nmin_peptides Int Minimum number of peptides required for a protein group (default: 1)","category":"page"},{"location":"user_guide/parameters/#MaxLFQ-Parameters","page":"Parameter Configuration","title":"MaxLFQ Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nrun_to_run_normalization Boolean Whether to use run-to-run normalized abundances for precursor and protein quantification (default: false)","category":"page"},{"location":"user_guide/parameters/#Output-Parameters","page":"Parameter Configuration","title":"Output Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nwrite_csv Boolean Whether to write results to CSV (default: true)\nwrite_decoys Boolean Whether to quantify and include decoys in the output files (default: false)\ndelete_temp Boolean Whether to delete temporary files (default: true)\nplots_per_page Int Number of plots per page in reports (default: 12)","category":"page"},{"location":"user_guide/parameters/#Logging-Parameters","page":"Parameter Configuration","title":"Logging Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\ndebug_console_level Int Verbosity of console debug output (0 disables; higher values include more details).\nmax_message_bytes Int Maximum bytes of a single log message before truncation (default: 4096). Truncation preserves valid UTF-8 and appends a suffix like … [truncated N bytes]. Can be overridden at runtime with PIONEER_MAX_LOG_MSG_BYTES (values clamped to [1024, 1048576]).","category":"page"},{"location":"user_guide/parameters/#Path-Parameters","page":"Parameter Configuration","title":"Path Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nlibrary String Path to spectral library file\nms_data String Path to mass spectrometry data directory\nresults String Path to output results directory","category":"page"},{"location":"user_guide/parameters/#BuildSpecLib-Configuration","page":"Parameter Configuration","title":"BuildSpecLib Configuration","text":"","category":"section"},{"location":"user_guide/parameters/#FASTA-Input-and-Regex-Mapping","page":"Parameter Configuration","title":"FASTA Input and Regex Mapping","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Pioneer supports flexible FASTA input through GetBuildLibParams:","category":"page"},{"location":"user_guide/parameters/#Input-Options","page":"Parameter Configuration","title":"Input Options","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Single directory: Scans for all .fasta and .fasta.gz files\nSingle file: Directly uses the specified FASTA file\nMixed array: Any combination of directories and files","category":"page"},{"location":"user_guide/parameters/#Regex-Code-Mapping","page":"Parameter Configuration","title":"Regex Code Mapping","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"The regex patterns for parsing FASTA headers can be configured in three ways:","category":"page"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Single regex set for all files (default):\nGetBuildLibParams(out_dir, lib_name, [dir1, dir2, file1])\n# All FASTA files use the same default regex patterns\nCustom single regex set:\nGetBuildLibParams(out_dir, lib_name, [dir1, file1],\n    regex_codes = Dict(\n        \"accessions\" => \"^>(\\\\S+)\",\n        \"genes\" => \"GN=(\\\\S+)\",\n        \"proteins\" => \"\\\\s+(.+?)\\\\s+OS=\",\n        \"organisms\" => \"OS=(.+?)\\\\s+GN=\"\n    ))\n# All files use these custom patterns\nPositional mapping (one regex set per input):\nGetBuildLibParams(out_dir, lib_name, [uniprot_dir, custom_file],\n    regex_codes = [\n        Dict(\"accessions\" => \"^\\\\w+\\\\|(\\\\w+)\\\\|\", ...),  # For uniprot_dir files\n        Dict(\"accessions\" => \"^>(\\\\S+)\", ...)             # For custom_file\n    ])","category":"page"},{"location":"user_guide/parameters/#FASTA-Digest-Parameters","page":"Parameter Configuration","title":"FASTA Digest Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nmin_length Int Minimum peptide length (default: 7)\nmax_length Int Maximum peptide length (default: 30)\nmin_charge Int Minimum charge state (default: 2)\nmax_charge Int Maximum charge state (default: 4)\ncleavage_regex String Regular expression for cleavage sites (default: \"[KR][^_| to exclude cleavage after proline KR^P]\")\nmissed_cleavages Int Maximum allowed missed cleavages (default: 1)\nmax_var_mods Int Maximum variable modifications per peptide (default: 1)\nadd_decoys Boolean Generate decoy sequences (default: true)\nentrapment_r Float Ratio of entrapment sequences (default: 0)\ndecoy_method String Method for generating decoy sequences: \"shuffle\" or \"reverse\" (default: \"shuffle\")\nentrapment_method String Method for generating entrapment sequences: \"shuffle\" or \"reverse\" (default: \"shuffle\")\nfasta_header_regex_accessions [String] Regex with a capture group for the accession, one per FASTA file\nfasta_header_regex_genes [String] Regex with a capture group for the gene name, one per FASTA file\nfasta_header_regex_proteins [String] Regex with a capture group for the protein name, one per FASTA file\nfasta_header_regex_organisms [String] Regex with a capture group for the organism, one per FASTA file","category":"page"},{"location":"user_guide/parameters/#NCE-Parameters","page":"Parameter Configuration","title":"NCE Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nnce Float Base normalized collision energy (default: 26.0)\ndefault_charge Int Default charge state for NCE calculations (default: 2)\ndynamic_nce Boolean Use charge-dependent NCE adjustments (default: true)","category":"page"},{"location":"user_guide/parameters/#Library-Parameters","page":"Parameter Configuration","title":"Library Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nrt_bin_tol Float Retention time binning tolerance in minutes (default: 1.0)\nfrag_bin_tol_ppm Float Fragment mass tolerance in PPM (default: 10.0)\nrank_to_score [Int] Intensity multipliers for ranked peaks (default: [8,4,4,2,2,1,1])\ny_start_index Int Starting index for y-ion annotation (default: 4)\nb_start_index Int Starting index for b-ion annotation (default: 3)\ny_start Int Minimum y-ion to consider (default: 3)\nb_start Int Minimum b-ion to consider (default: 2)\ninclude_p_index Boolean Include proline-containing index fragments (default: false)\ninclude_p Boolean Include proline-containing fragments (default: false)\nauto_detect_frag_bounds Boolean Auto-detect fragment mass bounds from calibration file (default: true)\nfrag_mz_min Float Minimum fragment m/z (default: 150.0)\nfrag_mz_max Float Maximum fragment m/z (default: 2020.0)\nprec_mz_min Float Minimum precursor m/z (default: 390.0)\nprec_mz_max Float Maximum precursor m/z (default: 1010.0)\nmax_frag_charge Int Maximum fragment ion charge (default: 3)\nmax_frag_rank Int Maximum fragment rank (default: 255)\nlength_to_frag_count_multiple Float Multiplier for peptide length to determine fragment count (default: 2)\nmin_frag_intensity Float Minimum relative fragment intensity (default: 0.00)\ninclude_isotope Boolean Include isotope peak annotations (default: false)\ninclude_internal Boolean Include internal fragment annotations (default: false)\ninclude_immonium Boolean Include immonium ion annotations (default: false)\ninclude_neutral_diff Boolean Include neutral loss annotations (default: true)\ninstrument_type String Instrument type for predictions (default: \"NONE\")\nprediction_model String Model for fragment predictions (default: \"altimeter\")","category":"page"},{"location":"user_guide/parameters/#Modification-Parameters","page":"Parameter Configuration","title":"Modification Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nvariable_mods.pattern [String] Amino acids to modify (default: [\"M\"])\nvariable_mods.mass [Float] Modification masses (default: [15.99491])\nvariable_mods.name [String] Modification identifiers (default: [\"Unimod:35\"])\nfixed_mods.pattern [String] Amino acids to modify (default: [\"C\"])\nfixed_mods.mass [Float] Modification masses (default: [57.021464])\nfixed_mods.name [String] Modification identifiers (default: [\"Unimod:4\"])\nisotope_mod_groups [Object] Isotope labeling groups for multiplexed experiments (default: [])","category":"page"},{"location":"user_guide/parameters/#Processing-Parameters","page":"Parameter Configuration","title":"Processing Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nmax_koina_requests Int Maximum concurrent Koina API requests (default: 24)\nmax_koina_batch Int Maximum batch size for API requests (default: 1000)\nmatch_lib_build_batch Int Batch size for library building (default: 100000)","category":"page"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"note: Koina API Retry Behavior\nAs of version 0.1.13, Koina API retry warnings are now logged at debug level 2 instead of being shown to users by default. To see retry attempts during debugging, set debug_console_level: 2 in your SearchDIA parameters. The library build will only fail if all retry attempts are exhausted.","category":"page"},{"location":"user_guide/parameters/#Path-Parameters-2","page":"Parameter Configuration","title":"Path Parameters","text":"","category":"section"},{"location":"user_guide/parameters/","page":"Parameter Configuration","title":"Parameter Configuration","text":"Parameter Type Description\nlibrary_path String Output path for the spectral library\nfasta_paths [String] List of FASTA file or directory paths\nfasta_names [String] Names for each FASTA file\ncalibration_raw_file String Path to calibration Arrow file for automatic m/z range detection (optional)\ninclude_contaminants Boolean Append a contaminants FASTA to the build (default: true)\npredict_fragments Boolean Predict fragment intensities (default: true)","category":"page"},{"location":"user_guide/installation/#Installation-Guide","page":"Installation Guide","title":"Installation Guide","text":"","category":"section"},{"location":"user_guide/installation/#System-Requirements","page":"Installation Guide","title":"System Requirements","text":"","category":"section"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"CPU: Multiple cores and threads recommended. Increasing the number of threads reduces computation time.\nRAM: >=16GB recommended. RAM availability should exceed the spectral library size by at least 4GB. For searching against the yeast proteome, as little as 6-8 GB may suffice.\nStorage: SSD recommended. Available disk space at least double the total size of the .arrow formatted raw files to search. The .arrow files are usually ~1/2 the size of the vendor files.\nOperating System: Windows, Linux, or macOS","category":"page"},{"location":"user_guide/installation/#Installation","page":"Installation Guide","title":"Installation","text":"","category":"section"},{"location":"user_guide/installation/#End-User-Installation","page":"Installation Guide","title":"End-User Installation","text":"","category":"section"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"Download the installer for your operating system from the releases page:\nWindows – .msi installer\nmacOS – .pkg installer (signed and notarized); separate builds for Intel and Apple Silicon\nLinux – .deb package\nRun the installer. It places a pioneer executable on your PATH.\nOn first launch:\nmacOS – Gatekeeper verifies the binary and the first run can take about a minute. Zipped binaries require manual Gatekeeper approval and are not recommended.\nVerify the installation:\npioneer --help\nUse --threads N to control the number of worker threads:\npioneer search --threads 8 ...","category":"page"},{"location":"user_guide/installation/#Docker","page":"Installation Guide","title":"Docker","text":"","category":"section"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"Run Pioneer in a container without installing dependencies.","category":"page"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"Pull the prebuilt image:\ndocker pull dennisgoldfarb/pioneer:latest\nExecute Pioneer inside the container, mounting a host directory (e.g. the current directory) to access data:\ndocker run --rm -it -v $(pwd):/work dennisgoldfarb/pioneer:latest pioneer --help\nReplace pioneer --help with any subcommand.\nTo build the image locally using the included Dockerfile:\ndocker build -t pioneer .","category":"page"},{"location":"user_guide/installation/#Development-Setup","page":"Installation Guide","title":"Development Setup","text":"","category":"section"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"To work on Pioneer itself, set up a local development environment.","category":"page"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"Install Julia 1.10 or higher from julialang.org (only required for development; compiled releases bundle their own runtime).\nClone the repository:\ngit clone https://github.com/nwamsley1/Pioneer.jl.git\ncd Pioneer.jl\nStart Julia in the development environment and activate the project:\njulia --project=dev\npkg> develop ./\nIn the Julia REPL load Revise and Pioneer:\njulia> using Revise, Pioneer\nInstall PioneerConverter to convert Thermo RAW files to Arrow format.\nCall the main functions directly, e.g.\n# Option 1: Single FASTA directory (backward compatible)\nparams = GetBuildLibParams(out_dir, lib_name, fasta_dir)\nBuildSpecLib(params)\n\n# Option 2: Flexible input - files and/or directories\nparams = GetBuildLibParams(out_dir, lib_name, \n    [\"/path/to/dir1\", \"/path/to/file.fasta\", \"/path/to/dir2\"])\nBuildSpecLib(params)\nparams = GetSearchParams(\"library.poin\", \"ms_data\", \"results\")\nSearchDIA(params)","category":"page"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"Subcommand Julia function\nparams-predict GetBuildLibParams\npredict BuildSpecLib\nparams-search GetSearchParams\nsearch SearchDIA\nconvert-raw PioneerConverter\nconvert-mzml convertMzML","category":"page"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"note: Note\nRevise enables hot reloading of code during development.","category":"page"},{"location":"user_guide/installation/#PioneerConverter","page":"Installation Guide","title":"PioneerConverter","text":"","category":"section"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"Detailed installation and usage instructions for PioneerConverter are available in its documentation.","category":"page"},{"location":"user_guide/installation/#Next-Steps","page":"Installation Guide","title":"Next Steps","text":"","category":"section"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"After installation:","category":"page"},{"location":"user_guide/installation/","page":"Installation Guide","title":"Installation Guide","text":"Follow the Quick Start Tutorial.\nGenerate parameter files with pioneer params-predict or pioneer params-search, then edit them according to Parameter Configuration.","category":"page"},{"location":"advanced/performance/#Performance-Tuning","page":"Performance Tuning","title":"Performance Tuning","text":"","category":"section"},{"location":"user_guide/quickstart/#Quick-Start-Tutorial","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"","category":"section"},{"location":"user_guide/quickstart/#Basic-Workflow","page":"Quick Start Tutorial","title":"Basic Workflow","text":"","category":"section"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"Pioneer performs three major steps:","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"Convert vendor MS files into the Arrow format using PioneerConverter.\nBuild in silico spectral libraries using FASTA files and the Koina server.\nSearch DIA experiments using a spectral library and the MS data files.","category":"page"},{"location":"user_guide/quickstart/#Pioneer-Converter","page":"Quick Start Tutorial","title":"Pioneer Converter","text":"","category":"section"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"Pioneer operates on MS/MS data stored in the Apache Arrow IPC format. Use the bundled PioneerConverter via the CLI to convert Thermo RAW files:","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"pioneer convert-raw /path/to/raw/or/folder","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"This subcommand accepts either a single .raw file or a directory of files. See the PioneerConverter repository for additional options such as thread count and output paths.","category":"page"},{"location":"user_guide/quickstart/#MzML-to-Arrow-IPC-(Sciex)","page":"Quick Start Tutorial","title":"MzML to Arrow IPC (Sciex)","text":"","category":"section"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"For mzML-formatted data, use:","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"pioneer convert-mzml /path/to/mzml/or/folder","category":"page"},{"location":"user_guide/quickstart/#Starting-Pioneer","page":"Quick Start Tutorial","title":"Starting Pioneer","text":"","category":"section"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"After installation, Pioneer is accessed from the command line. Running pioneer --help displays available subcommands:","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"pioneer [options] <subcommand> [subcommand-args...]","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"Subcommands include search, predict, params-search, params-predict, convert-raw, and convert-mzml. On the first launch macOS performs a one-time Gatekeeper check.","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"A minimal end-to-end workflow is:","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"# Generate library build parameters (library name derived from output path)\npioneer params-predict lib_dir fasta_dir --params-path=predict_params.json\n\n# Edit predict_params.json to customize:\n# - Digestion parameters (missed cleavages, modifications, etc.)\n# - For multiple FASTA sources, edit fasta_paths array to include directories and/or files\n# - Set calibration file if available for automatic m/z range detection\n\npioneer predict predict_params.json\npioneer convert-raw raw_dir\npioneer params-search library.poin ms_data_dir results_dir --params-path=search_params.json\npioneer search search_params.json","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"This sequence builds a predicted spectral library, converts vendor files to Arrow, generates search parameters, and searches the experiment.","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"tip: Advanced FASTA Input\nThe CLI takes a single path (file or directory). For multiple FASTA sources (directories and/or files), edit the fasta_paths array in the generated JSON parameter file.When using the Julia API directly, you can specify mixed sources at creation:params = GetBuildLibParams(out_dir, lib_name,\n    [\"/path/to/uniprot/\", \"/custom/proteins.fasta\"])Note: CLI users don't specify lib_name - it's automatically derived from out_dir.","category":"page"},{"location":"user_guide/quickstart/","page":"Quick Start Tutorial","title":"Quick Start Tutorial","text":"params-predict and params-search create template JSON files. Edit these configurations to suit your experiment before running predict or search. See Parameter Configuration for a description of each option.","category":"page"},{"location":"advanced/algorithms/#algorithm-documentation","page":"Algorithm Documentation","title":"Algorithm Documentation","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Supplemental-Methods-Review:-all_methods.tex","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Document Reviewed: all_methods.tex Review Date: 2025-10-30 Total Issues Found: 28","category":"page"},{"location":"supplemental_methods/methods_review/#Table-of-Contents","page":"Supplemental Methods Review: all_methods.tex","title":"Table of Contents","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Missing or Incomplete Cross-References (6 issues)\nHard-Coded Section/Equation Numbers (5 issues)\nTypos and Duplicate Words (4 issues)\nIncomplete Citations (1 issue)\nTerminology Inconsistency (1 category)\nPotential Conceptual Confusion (1 major issue)\nMathematical Notation Issues (2 issues)\nUnclear Explanations (2 issues)\nIndex Inconsistency (2 issues)","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#1.-Missing-or-Incomplete-Cross-References","page":"Supplemental Methods Review: all_methods.tex","title":"1. Missing or Incomplete Cross-References","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-1.1:-Missing-reference-to-linear-regression-section","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 1.1: Missing reference to linear regression section","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 867\nPriority: HIGH\nCurrent text:\nPioneer does this by first repeating the linear regression of mass spectra onto the library spectra \\ref{REFHERE}\nProblem: Placeholder reference \\ref{REFHERE}\nRecommended fix: Replace with \\ref{sec:linear_regression} (defined at line 573)\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-1.2:-Missing-reference-to-isotope-trace-selection","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 1.2: Missing reference to isotope trace selection","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 873\nPriority: HIGH\nCurrent text:\nThe isotope trace pattern to integrate for each precursor is selected as described in \\ref{ref here}.\nProblem: Placeholder reference \\ref{ref here}\nRecommended fix: Replace with \\ref{subsubsec:best-isotope-trace-selection} (defined at line 825)\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-1.3:-Empty-reference-to-isotope-correction","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 1.3: Empty reference to isotope correction","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 875\nPriority: HIGH\nCurrent text:\nSee section \\ref{} for documentation on correcting the abundance of separate isotope traces.\nProblem: Empty reference \\ref{}\nRecommended fix: Replace with \\ref{subsec:fragment-isotope-correction} (defined at line 1078)\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-1.4:-Outdated-label-reference-in-protein-inference-input","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 1.4: Outdated label reference in protein inference input","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 919\nPriority: HIGH\nCurrent text:\nfrom the two-stage FDR control described in Section~\\ref{subsec2}\nProblem: References old label subsec2 that was changed during label standardization\nRecommended fix: Replace with \\ref{subsec:target-decoy-mbr-fdr} (defined at line 603)\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-1.5:-Outdated-label-reference-in-protein-peptide-bipartite-graph","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 1.5: Outdated label reference in protein-peptide bipartite graph","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 932\nPriority: HIGH\nCurrent text:\nLet $\\mathcal{A}$ denote the set of all protein accession numbers in the spectral library (as defined in Section~\\ref{subsec2})\nProblem: References old label subsec2 - ambiguous which section is intended\nRecommended fix:\nIf referring to protein groups definition: Replace with \\ref{subsec:spectral-library-sequence-generation} (line 176)\nIf referring to the set mathcalA definition: Add explicit label where mathcalA is first defined\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-1.6:-Missing-reference-to-MBR-iteration-explanation","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 1.6: Missing reference to MBR iteration explanation","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 754\nPriority: MEDIUM\nCurrent text:\nLet $\\text{prob}_{p,i,r}^{\\text{test},(2)}$ be the out-of-fold probabilities from iteration 2 (before full MBR feature refinement)\nProblem: \"iteration 2\" is mentioned without reference to where iterations are explained\nRecommended fix: Add reference: from iteration 2 (before full MBR feature refinement, see Section~\\ref{subsubsec:iterative-model-training})\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#2.-Hard-Coded-Section/Equation-Numbers","page":"Supplemental Methods Review: all_methods.tex","title":"2. Hard-Coded Section/Equation Numbers","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-2.1:-Red-placeholder-text-for-precursor-isotope-estimation","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 2.1: Red placeholder text for precursor isotope estimation","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 80\nPriority: HIGH\nCurrent text:\nprecursor isotope contributions were estimated using the approach described \\textbf{\\textcolor{red}{elsewhere in the Methods}}\nProblem: Red placeholder text indicating missing reference\nRecommended fix: Replace with described in Section~\\ref{subsubsec:estimating-precursor-isotope-abundances}\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-2.2:-Hard-coded-equation-number-reference","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 2.2: Hard-coded equation number reference","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1100\nPriority: MEDIUM\nCurrent text:\nIn practice, Pioneer truncates the sum in equation 37 at $p=5$\nProblem: Hard-coded equation number \"37\" instead of using LaTeX reference\nRecommended fix: Replace with in Equation~\\eqref{eq:fragment-isotope-conditional} and add label to equation at line 1097\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-2.3:-Hard-coded-subsection-numbers","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 2.3: Hard-coded subsection numbers","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1129\nPriority: MEDIUM\nCurrent text:\nWe propose a solution in subsection 4.14.2. Subsection 4.14.1 describes how to estimate each $x_{i}^{k}$.\nProblem: Hard-coded subsection numbers \"4.14.2\" and \"4.14.1\"\nRecommended fix: Replace with:\nWe propose a solution in Section~\\ref{subsubsec:asymmetric-generalized-bell-function}. Section~\\ref{subsubsec:estimating-precursor-isotope-abundances} describes how to estimate each $x_{i}^{k}$.\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-2.4:-Hard-coded-equation-number-in-quadrupole-transmission","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 2.4: Hard-coded equation number in quadrupole transmission","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1188\nPriority: MEDIUM\nCurrent text:\nPioneer minimizes the squared error between the respective natural logarithms of $R(x_0, x_1)$ and the data as in equation (33).\nProblem: Hard-coded equation number \"(33)\"\nRecommended fix: Add label \\label{eq:quadrupole-ratio} to equation at line 1126, then replace with as in Equation~\\eqref{eq:quadrupole-ratio}\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-2.5:-External-equation-reference","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 2.5: External equation reference","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1094\nPriority: LOW (external reference)\nCurrent text:\nand given equation 3.5 from Goldfarb, D. we have the following:\nProblem: References external equation from citation\nRecommended fix: Keep as-is (external reference is acceptable) OR add citation: equation 3.5 from \\citet{Goldfarb2018-ai}\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#3.-Typos-and-Duplicate-Words","page":"Supplemental Methods Review: all_methods.tex","title":"3. Typos and Duplicate Words","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-3.1:-Duplicate-word-\"isotopes\"","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 3.1: Duplicate word \"isotopes\"","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1100\nPriority: HIGH\nCurrent text:\nsince the first 5 isotopes isotopes account for\nProblem: Duplicate word \"isotopes isotopes\"\nRecommended fix: Remove one instance: since the first 5 isotopes account for\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-3.2:-Duplicate-word-\"the\"","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 3.2: Duplicate word \"the\"","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1137\nPriority: HIGH\nCurrent text:\nconditional abundance of $l$-th isotope of the the $j$-th fragment\nProblem: Duplicate word \"the the\"\nRecommended fix: Remove one instance: conditional abundance of $l$-th isotope of the $j$-th fragment\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-3.3:-Grammar-error-\"for-and-observed\"","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 3.3: Grammar error \"for and observed\"","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1149\nPriority: HIGH\nCurrent text:\nNow for and observed MS/MS spectrum\nProblem: Grammar error \"for and\" should be \"for an\"\nRecommended fix: Now for an observed MS/MS spectrum\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-3.4:-Duplicate-word-\"using\"","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 3.4: Duplicate word \"using\"","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1086\nPriority: HIGH\nCurrent text:\nusing using sulfur-specific splines\nProblem: Duplicate word \"using using\"\nRecommended fix: Remove one instance: using sulfur-specific splines\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#4.-Incomplete-Citations","page":"Supplemental Methods Review: all_methods.tex","title":"4. Incomplete Citations","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-4.1:-Placeholder-citation-for-LightGBM","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 4.1: Placeholder citation for LightGBM","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 605\nPriority: HIGH\nCurrent text:\nPioneer trains LightGBM target-decoy discrimination models using cross-validation to score each precursor isotope trace \\cite{LightGBM paper...}.\nProblem: Incomplete placeholder citation \\cite{LightGBM paper...}\nRecommended fix: Replace with proper citation. The official LightGBM paper is:\n\\cite{Ke2017-lightgbm}\nCitation: Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., & Liu, T. Y. (2017). LightGBM: A highly efficient gradient boosting decision tree. In Advances in Neural Information Processing Systems (pp. 3146-3154).\nStatus: [x] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#5.-Terminology-Inconsistency","page":"Supplemental Methods Review: all_methods.tex","title":"5. Terminology Inconsistency","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-5.1:-\"Parent-ion\"-vs-\"Precursor\"-terminology","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 5.1: \"Parent ion\" vs \"Precursor\" terminology","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Lines: 211-213, 537, 539, 544\nPriority: MEDIUM\nCurrent text: Uses \"parent ion\" in several locations:\nLine 211: $P_k \\in \\mathbb{N}$ uniquely identifies the parent ion\nLine 212: $M_k \\in \\mathbb{R}^+$ is the parent ion m/z\nLine 213: $Z_k \\in  \\mathbb{N}^+$ is the parent ion charge\nLine 537: for parent ions within a specified mass-to-charge\nLine 539: $j_k^{(F)}$ identifies the parent ion for each fragment\nLine 544: $j^{(F_{m})}, j_k^{(F_{u})}$ identifies the parent ion\nProblem: Rest of document consistently uses \"precursor\" terminology\nRecommended fix: Replace all instances of \"parent ion\" with \"precursor\" for consistency\nImpact: This affects Fragment Index Search (lines 189-284) and Matrix Representation sections (lines 535-599)\nStatus: [ ] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#6.-Potential-Conceptual-Confusion","page":"Supplemental Methods Review: all_methods.tex","title":"6. Potential Conceptual Confusion","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-6.1:-Dual-definition-of-\"protein-group\"","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 6.1: Dual definition of \"protein group\"","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Lines: 179 (first definition) and 913+ (second context)\nPriority: HIGH (conceptual clarity)\nProblem: \"Protein group\" is defined in two different contexts with potentially different meanings:\nDefinition 1 (Line 179) - During spectral library construction:\nPioneer defines a protein group as the maximal set of UniProt accession numbers\nin the sequence database that uniquely correspond to a maximal set of peptide\nsequences through the sequence digestion process.\nThis is a pre-computed grouping based on theoretical digestion of the FASTA database.\nDefinition 2 (Lines 913-1034) - During protein inference:\nPioneer implements a two-phase parsimony-based inference algorithm to identify\na minimal set of protein groups that explains all observed peptides.\nThis is an inferred grouping based on observed peptides after FDR control.\nConceptual issue: These appear to be different concepts:\nLibrary protein groups: Pre-defined during library construction (all theoretically possible peptides)\nInferred protein groups: Discovered from actually observed peptides\nQuestions needing clarification:\nAre library protein groups used to constrain the inference process?\nCan inferred protein groups differ from library protein groups?\nWhat happens if observed peptides map to proteins in different library groups?\nRecommended fix:\nOption A: Use distinct terminology (e.g., \"library protein group\" vs \"inferred protein group\")\nOption B: Add a paragraph explicitly describing the relationship between these two definitions\nOption C: Clarify that line 179 defines groups for CV fold assignment (line 611) but inference independently discovers groups\nStatus: [ ] Needs author clarification and revision","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#7.-Mathematical-Notation-Issues","page":"Supplemental Methods Review: all_methods.tex","title":"7. Mathematical Notation Issues","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-7.1:-Undefined-parameters-in-quadrupole-transmission-function","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 7.1: Undefined parameters in quadrupole transmission function","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Lines: 1088-1094\nPriority: MEDIUM\nCurrent text:\nPioneer models the transmission efficiency of each precursor isotope with which\nthe quadrupole transmits each precursor isotope. The quadrupole transmission\nfunction is defined as the following:\n\\begin{equation}\n    Q(z^{p}; c, w) = \\Pr\\bigl( P=p \\mid Q)\n\\end{equation}\nProblem:\nParameters c and w are used in function signature but never defined in the text\nRedundant phrasing: \"transmission efficiency...with which the quadrupole transmits\"\nLater (line 1114) they are mentioned as \"centered at c, with an isolation width, w\" but not when first introduced\nRecommended fix:\nDefine parameters when first introducing the function:\nThe quadrupole transmission function, $Q(z^{p}; c, w)$, is defined as follows,\nwhere $c$ is the center of the isolation window and $w$ is the isolation width:\nSimplify redundant text to: \"Pioneer models the transmission efficiency with which the quadrupole transmits each precursor isotope.\"\nStatus: [ ] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-7.2:-Missing-word-in-sentence-about-bad-transfers","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 7.2: Missing word in sentence about bad transfers","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 769\nPriority: HIGH\nCurrent text:\nFirst, target isotope traces transferring identifications their paired decoy isotope traces.\nProblem: Missing the word \"to\" between \"identifications\" and \"their\"\nRecommended fix: target isotope traces transferring identifications to their paired decoy isotope traces\nStatus: [ ] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#8.-Unclear-Explanations","page":"Supplemental Methods Review: all_methods.tex","title":"8. Unclear Explanations","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-8.1:-Undefined-statistical-notation","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 8.1: Undefined statistical notation","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 334\nPriority: MEDIUM\nCurrent text:\n\\delta_{\\text{RT}} = \\frac{4}{\\Phi(3/4)^{-1}} \\cdot \\text{MAD}\nProblem: Phi is not defined in the text\nClarification needed: Phi is the cumulative distribution function (CDF) of the standard normal distribution, and Phi^-1 is its inverse (the quantile function)\nRecommended fix: Add explanation:\nwhere $\\Phi^{-1}$ is the inverse cumulative distribution function (quantile function)\nof the standard normal distribution.\nStatus: [ ] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-8.2:-Incomplete-explanation-of-slope-property","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 8.2: Incomplete explanation of slope property","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 1176\nPriority: LOW\nCurrent text:\nThe shape parameters $b_l$ and $b_r$ determine the smoothness of the transition,\nsuch that the slope $-b_l/(2a_l)$ at $x = a_l$ and $-b_r/(2a_r)$ at $x = a_r$.\nProblem: Sentence is incomplete - \"such that the slope...\" doesn't finish the thought. What about the slope? Is this the slope at the half-maximum point?\nRecommended fix: Complete the sentence or clarify what property of the slope is being described:\nThe shape parameters $b_l$ and $b_r$ determine the smoothness of the transition,\nwith the derivative at the half-maximum points ($x = \\pm a_{l/r}$) being\n$-b_l/(2a_l)$ and $-b_r/(2a_r)$ respectively.\nStatus: [ ] Consider revision for clarity","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#9.-Index-Inconsistency","page":"Supplemental Methods Review: all_methods.tex","title":"9. Index Inconsistency","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Issue-9.1:-Inconsistent-index-variable-in-set-definition","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 9.1: Inconsistent index variable in set definition","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 539\nPriority: MEDIUM\nCurrent text:\nPioneer combines the library fragmentation spectra, $L_j$, into a single set,\n$F = \\{(I_i^{(F)}, Z_i^{(F)}, j_i^{(F)})\\}_{k=1}^{T}$\nProblem: Set elements use index i in superscripts (I_i^(F) Z_i^(F) j_i^(F)) but the set range uses index k with _k=1^T\nRecommended fix: Make consistent - either:\nChange to: $F = \\{(I_k^{(F)}, Z_k^{(F)}, j_k^{(F)})\\}_{k=1}^{T}$, OR\nChange to: $F = \\{(I_i^{(F)}, Z_i^{(F)}, j_i^{(F)})\\}_{i=1}^{T}$\nNote: Check subsequent usage to determine which index is used consistently\nStatus: [ ] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/#Issue-9.2:-Missing-subscript-in-notation","page":"Supplemental Methods Review: all_methods.tex","title":"Issue 9.2: Missing subscript in notation","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Line: 544\nPriority: MEDIUM\nCurrent text:\n\\item $j^{(F_{m})}, j_k^{(F_{u})}$ identifies the parent ion\nProblem: First notation $j^{(F_{m})}$ is missing the subscript k to match the pattern\nRecommended fix: $j_k^{(F_{m})}, j_k^{(F_{u})}$ identifies the parent ion\nStatus: [ ] Fixed","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#Summary-Statistics","page":"Supplemental Methods Review: all_methods.tex","title":"Summary Statistics","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Category Count High Priority Medium Priority Low Priority\nMissing Cross-References 6 5 1 0\nHard-Coded Numbers 5 1 3 1\nTypos/Duplicates 4 4 0 0\nIncomplete Citations 1 1 0 0\nTerminology Issues 1 0 1 0\nConceptual Confusion 1 1 0 0\nNotation Issues 2 1 1 0\nUnclear Explanations 2 0 1 1\nIndex Inconsistency 2 0 2 0\nTOTAL 28 13 9 2","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#Recommended-Order-of-Fixes","page":"Supplemental Methods Review: all_methods.tex","title":"Recommended Order of Fixes","text":"","category":"section"},{"location":"supplemental_methods/methods_review/#Phase-1:-Critical-Fixes-(Do-First)","page":"Supplemental Methods Review: all_methods.tex","title":"Phase 1: Critical Fixes (Do First)","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Fix all typos and duplicate words (Issues 3.1-3.4)\nFix missing cross-references (Issues 1.1-1.6)\nAdd LightGBM citation (Issue 4.1)\nFix missing word in line 769 (Issue 7.2)","category":"page"},{"location":"supplemental_methods/methods_review/#Phase-2:-Important-Clarifications","page":"Supplemental Methods Review: all_methods.tex","title":"Phase 2: Important Clarifications","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Clarify protein group definition confusion (Issue 6.1) - requires author input\nReplace hard-coded equation/section numbers (Issues 2.1-2.4)\nDefine quadrupole transmission parameters (Issue 7.1)\nFix index inconsistencies (Issues 9.1-9.2)","category":"page"},{"location":"supplemental_methods/methods_review/#Phase-3:-Polish","page":"Supplemental Methods Review: all_methods.tex","title":"Phase 3: Polish","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Standardize terminology (Issue 5.1)\nAdd statistical notation clarification (Issue 8.1)\nImprove incomplete explanation (Issue 8.2)\nConsider external citation addition (Issue 2.5)","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/#Notes-for-Authors","page":"Supplemental Methods Review: all_methods.tex","title":"Notes for Authors","text":"","category":"section"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"High priority items are errors that would confuse readers or cause compilation issues\nMedium priority items improve clarity and maintainability\nLow priority items are minor enhancements\nIssue 6.1 (protein group definition) may require input from the lead author about intended meaning\nConsider adding equation labels proactively to all numbered equations for future referencing\nThe document currently has 80 equations - ensure all important ones have labels","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/methods_review/","page":"Supplemental Methods Review: all_methods.tex","title":"Supplemental Methods Review: all_methods.tex","text":"Review completed: 2025-10-30 Reviewer notes: This is a well-structured mathematical document with excellent use of formalism. The issues identified are primarily housekeeping items (references, typos) rather than fundamental problems with the methodology.","category":"page"},{"location":"supplemental_methods/missing_sections/#Missing-Sections-and-Content-Gaps:-all_methods.tex","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Document Reviewed: all_methods.tex Review Date: 2025-10-30 Review Type: Content Completeness Analysis","category":"page"},{"location":"supplemental_methods/missing_sections/#Purpose","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Purpose","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"This document identifies missing content and gaps in the supplemental methods documentation. It complements methods_review.md (which focuses on fixing existing content) by cataloging content that should be added to make the methods section complete and reproducible.","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#Table-of-Contents","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Table of Contents","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Critical Missing Content (3 items)\nRecommended Additional Sections (6 items)\nDocument Organization Issues (1 item)\nAction Items Summary","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#Critical-Missing-Content","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Critical Missing Content","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"These are essential components that are referenced but not explained, or are necessary for reproducibility.","category":"page"},{"location":"supplemental_methods/missing_sections/#1.-Chronologer-/-Retention-Time-Prediction-Model","page":"Missing Sections and Content Gaps: all_methods.tex","title":"1. Chronologer / Retention Time Prediction Model","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🔴 CRITICAL","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Problem: Chronologer is mentioned twice in the document but never explained:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Line 66: \"retention times were aligned to Chronologer predictions using spline fitting\"\nLine 177: \"Pioneer constructs target-decoy sequence libraries as inputs to Altimeter and Chronologer for in silico spectrum prediction\"","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Throughout the document, \"library retention time (iRT)\" and \"indexed retention time (iRT)\" are used extensively (50+ references), but their initial source is never explained.","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What is Chronologer?\nIs it a separate tool, or part of Pioneer?\nWhat is its relationship to Pioneer and Altimeter?\nHow does it work?\nWhat algorithm/model does it use for retention time prediction?\nWhat are its inputs and outputs?\nWhat training data was used?\nModel architecture (if machine learning-based)\nHow are iRT values assigned?\nHow does Pioneer obtain initial iRT predictions for library peptides?\nAre these predictions part of the spectral library generation?\nWhat happens if Chronologer predictions are unavailable?\nValidation and accuracy\nWhat is the typical prediction accuracy?\nHow robust is it across different instrument types or gradients?","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Option A: New subsection after Altimeter (between lines 149-169): \\subsection{Chronologer Retention Time Prediction}\nOption B: Clarify in the introduction that Chronologer is an external tool and cite appropriately\nOption C: Add as part of \"Spectral Library Sequence Generation\" (line 176)","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: HIGH - Without this information, readers cannot understand:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where iRT values come from\nHow to reproduce the analysis\nWhy retention time alignment works","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Needs to be added","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#2.-Fragment-Scoring-Function-Table-(Missing-Table)","page":"Missing Sections and Content Gaps: all_methods.tex","title":"2. Fragment Scoring Function Table (Missing Table)","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🔴 CRITICAL","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Problem: Referenced at line 204 but table does not exist:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Table~\\ref{tab:frag_score} gives the scoring function used throughout this work.","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing: A table showing the fragment scoring function that assigns weights based on fragment rank. The text says:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"\"Assign each fragment a score, s in mathbbN, based on its rank, r. The scoring function is user defined and ought to assign greater weights to the more probable fragment ions.\"","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Required Table Content: | Rank (r) | Score (s) | Description | |––––––|––––––-|––––––-| | 1 | ? | Top-ranked (most intense) fragment | | 2 | ? | Second-ranked fragment | | 3 | ? | Third-ranked fragment | | ... | ... | ... | | N | ? | Nth-ranked fragment |","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Or, if formulaic:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Provide the mathematical formula: s(r) = f(r)\nExplain the rationale (e.g., exponential decay, linear, etc.)\nState default values used in Pioneer","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"In Section 4 \"Intensity-Aware Fragment Index Search\" (around line 205)\nAdd after the text that references it\nLabel as \\label{tab:frag_score}","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: HIGH - This directly affects:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Fragment index scoring\nPSM ranking\nReproducibility of search results","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Needs to be added","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#3.-Spectral-Similarity-Scores-Table-(Missing-Table)","page":"Missing Sections and Content Gaps: all_methods.tex","title":"3. Spectral Similarity Scores Table (Missing Table)","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🔴 CRITICAL","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Problem: Referenced at line 389 but table does not exist:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"These include the spectral similarity scores listed in Table~\\ref{tab:simple_scores}","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"The text describes PSM features but doesn't list the spectral similarity scores.","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing: A table listing all spectral similarity metrics calculated by Pioneer for PSM scoring. Based on line 389, these are used as features in the first-pass search alongside:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Charge state\nNumber of missed cleavages\nNumber of variably oxidized methionines\nTotal ion current\nNumber of matched y ions\nMean fragment error\nNumber of peaks in the spectrum","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Required Table Content: | Feature Name | Description | Formula (if applicable) | Range | |–––––––|––––––-|––––––––––––|–––-| | Scribe Score | Intensity-weighted spectral similarity | (cited at line 354) | [0, 1] | | Cosine Similarity | ? | ? | [0, 1] | | Spectral Angle | ? | ? | [0, π/2] | | ... | ... | ... | ... |","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"In Section 6 \"First Pass Search\" (around line 389)\nAdd immediately after or before the text that references it\nLabel as \\label{tab:simple_scores}","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Note: Line 171 also references tab:simple_scores for \"Arrow table schema\" which seems incorrect - this may need to be a different table (tab:arrow_schema).","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: HIGH - These scores are critical features for:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"PSM discrimination\nProbit regression model training\nFDR estimation","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Needs to be added","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#Recommended-Additional-Sections","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Recommended Additional Sections","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"These sections would improve completeness and usability but are not critical for understanding the core algorithms.","category":"page"},{"location":"supplemental_methods/missing_sections/#4.-Software-and-Computational-Requirements","page":"Missing Sections and Content Gaps: all_methods.tex","title":"4. Software and Computational Requirements","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🟡 MEDIUM","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Hardware requirements\nMinimum RAM (likely substantial for LightGBM models and large datasets)\nRecommended CPU cores\nGPU support (if any for Altimeter inference)\nDisk space requirements\nSoftware dependencies\nJulia version requirements\nRequired Julia packages\nPython version (for Altimeter)\nExternal tools (e.g., ThermoRawFileParser version)\nOperating system support\nLinux, macOS, Windows compatibility\nKnown platform-specific issues\nRuntime expectations\nTypical runtime for different dataset sizes\nScalability considerations\nParallelization capabilities","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"New subsection at the beginning or end of methods\nCould be combined with \"Cross-Platform Mass Spectrometry File Conversion\" section","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: MEDIUM - Helps users determine if they have adequate resources","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Consider adding","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#5.-Output-File-Formats-and-Interpretation","page":"Missing Sections and Content Gaps: all_methods.tex","title":"5. Output File Formats and Interpretation","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🟡 MEDIUM","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Output file types\nWhat files does Pioneer produce?\nFile naming conventions\nDirectory structure\nFile format specifications\nCSV/TSV column descriptions\nArrow table schemas for outputs\nHDF5/Binary format specifications (if any)\nResult interpretation\nHow to interpret q-values\nUnderstanding protein group IDs\nInterpreting entrapment results\nQuality metrics in output","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"New subsection: \\subsection{Pioneer Output Files and Results Interpretation}\nCould be placed before or after \"Protein Inference and Quantification\"","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: MEDIUM - Important for users to understand and use results","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Consider adding","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#6.-Supported-Post-Translational-Modifications","page":"Missing Sections and Content Gaps: all_methods.tex","title":"6. Supported Post-Translational Modifications","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🟡 MEDIUM","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Fixed modifications\nWhich modifications are applied by default?\nCarbamidomethylation of cysteine?\nVariable modifications\nWhich PTMs are supported?\nMaximum number of variable modifications per peptide\nHow modifications affect:\nLibrary generation\nFragment ion prediction (Altimeter)\nMass calculations\nRetention time prediction (Chronologer)\nCustom modifications\nCan users define custom modifications?\nWhat parameters are needed?\nLocalization\nDoes Pioneer perform PTM localization?\nIf so, what algorithm/scoring is used?","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Current mentions in document:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Line 389: \"number of variably oxidized methionines\" - suggests methionine oxidation is supported\nNo other specific modifications mentioned","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"New subsection in or near \"Spectral Library Sequence Generation\" (line 176)\n\\subsubsection{Supported Modifications}","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: MEDIUM - Critical for users working with modified peptides","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Consider adding","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#7.-Supported-Instruments-and-Data-Acquisition-Parameters","page":"Missing Sections and Content Gaps: all_methods.tex","title":"7. Supported Instruments and Data Acquisition Parameters","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🟠 MEDIUM-LOW","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Instrument compatibility\nThermo instruments: which models?\nOther vendors through mzML conversion?\nInstrument-specific considerations\nFragmentation methods\nHCD (clearly supported - line 66)\nCID, ETD, EThcD?\nDoes Altimeter support non-HCD fragmentation?\nAcquisition parameters\nDIA window schemes supported\nOverlap vs. non-overlap windows\nNarrow windows: how narrow? (title mentions \"optimized for narrow isolation windows\")\nWide DIA compatibility?\nResolution requirements\nMS1 resolution\nMS2 resolution\nLow-resolution compatibility?","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Could expand \"Cross-Platform Mass Spectrometry File Conversion\" (line 169)\nOr add new subsection: \\subsection{Supported Instruments and Acquisition Methods}","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: MEDIUM-LOW - Helps users determine if Pioneer is appropriate for their data","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Consider adding","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#8.-Quality-Control-Metrics-and-Diagnostics","page":"Missing Sections and Content Gaps: all_methods.tex","title":"8. Quality Control Metrics and Diagnostics","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🟠 MEDIUM-LOW","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"QC metrics reported\nWhat QC metrics does Pioneer calculate?\nWhere are they reported?\nData quality assessment\nHow to assess if data quality is sufficient?\nWhat distributions should be examined?\nDiagnostic plots or outputs\nRecommended thresholds\nFDR thresholds used in benchmarks\nWhen to use stricter/looser thresholds\nQC metric thresholds for filtering\nTroubleshooting guidance\nWhat to do if few PSMs are identified?\nHow to diagnose poor RT alignment?\nWhen to adjust search parameters?","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"New section after methods: \\section{Quality Control and Diagnostics}\nOr integrate into existing sections where relevant","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: MEDIUM-LOW - Helps users ensure good results","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Consider adding","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#9.-Limitations-and-Known-Issues","page":"Missing Sections and Content Gaps: all_methods.tex","title":"9. Limitations and Known Issues","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🟢 LOW (but good practice for transparency)","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"What's Missing:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Method limitations\nDataset size limitations\nComputational complexity scaling\nWhen Pioneer might not be optimal\nKnown issues\nEdge cases\nKnown failure modes\nWorkarounds for common problems\nFuture improvements\nPlanned enhancements\nCurrent development limitations\nComparison to other methods\nWhen to use Pioneer vs. other DIA tools?\nSpecific advantages for narrow windows","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Where to Add:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Optional section at end of methods: \\subsection{Limitations and Considerations}\nOr in main manuscript discussion","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: LOW - Improves transparency and manages expectations","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Optional","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#Document-Organization-Issues","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Document Organization Issues","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/#10.-Incorrect-Table-Reference","page":"Missing Sections and Content Gaps: all_methods.tex","title":"10. Incorrect Table Reference","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Priority: 🟡 MEDIUM","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Problem: Line 171 references tab:simple_scores for Arrow table schema:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Pioneer-compatible arrow tables follow the schema in Table~\\ref{tab:simple_scores}.","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"However, tab:simple_scores is supposed to contain spectral similarity scores (line 389), not the Arrow schema.","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Solutions:","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Option A: Create two separate tables\ntab:arrow_schema - Arrow IPC format schema (referenced at line 171)\ntab:simple_scores - Spectral similarity scores (referenced at line 389)\nOption B: Fix the reference at line 171\nChange to reference a new table: Table~\\ref{tab:arrow_schema}\nAdd the Arrow schema table in the \"File Conversion\" section","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Recommended: Option A - create both tables","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Impact: MEDIUM - Causes confusion about what the table should contain","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Status: [ ] Needs correction","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#Action-Items-Summary","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Action Items Summary","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/#Phase-1:-Critical-Additions-(Do-First)","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Phase 1: Critical Additions (Do First)","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"[ ] 1.1 Add Chronologer explanation or clarify it's external and cite\n[ ] 1.2 Create Fragment Scoring Function Table (tab:frag_score)\n[ ] 1.3 Create Spectral Similarity Scores Table (tab:simple_scores)\n[ ] 1.4 Fix incorrect table reference at line 171 (create tab:arrow_schema)","category":"page"},{"location":"supplemental_methods/missing_sections/#Phase-2:-High-Value-Additions-(Strongly-Recommended)","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Phase 2: High-Value Additions (Strongly Recommended)","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"[ ] 2.1 Add Software/Computational Requirements section\n[ ] 2.2 Add Output File Formats section\n[ ] 2.3 Add Supported Modifications section","category":"page"},{"location":"supplemental_methods/missing_sections/#Phase-3:-Completeness-Improvements-(Optional)","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Phase 3: Completeness Improvements (Optional)","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"[ ] 3.1 Add Supported Instruments section\n[ ] 3.2 Add Quality Control Metrics section\n[ ] 3.3 Add Limitations section","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#Priority-Legend","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Priority Legend","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Symbol Priority Description\n🔴 CRITICAL Referenced but missing, or essential for reproducibility\n🟡 MEDIUM Important for usability and completeness\n🟠 MEDIUM-LOW Helpful but not essential\n🟢 LOW Nice to have for transparency","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/#Notes-for-Authors","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Notes for Authors","text":"","category":"section"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Chronologer - This is the #1 priority. Either:\nAdd a full methods section if it's part of your software suite\nAdd a brief explanation and citation if it's external/published\nExplain if iRT values are obtained differently (e.g., from external tools, manual annotation, etc.)\nMissing Tables - These are straightforward to add and are directly referenced in the text. Creating them will fix broken references and improve clarity.\nAdditional Sections - These would make the methods more complete, but prioritize based on:\nYour target audience\nJournal requirements\nSpace constraints\nWhether this information will be in supplementary materials vs. main text\nRelated Documents\nSee methods_review.md for issues with existing content (typos, references, etc.)\nThis document (missing_sections.md) focuses on content that should be added","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"","category":"page"},{"location":"supplemental_methods/missing_sections/","page":"Missing Sections and Content Gaps: all_methods.tex","title":"Missing Sections and Content Gaps: all_methods.tex","text":"Review completed: 2025-10-30 Reviewer notes: The algorithmic and mathematical content in the methods is excellent and comprehensive. The main gaps are practical/implementation details and the Chronologer component which is referenced but never explained.","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"In‑Memory MBR Candidate Labeling — Bug Analysis and Fix Proposal","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"This note explains why the in‑memory path is labeling far too many rows as match‑between‑runs (MBR) transfer candidates and how to correct it. The focus is on the in‑memory scorer in percolatorSortOf.jl and how it differs from the out‑of‑memory path that uses the correct logic.","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Where Candidates Are Labeled (In‑Memory)","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"File: src/utils/ML/percolatorSortOf.jl\nFunction: sort_of_percolator_in_memory!\nLocation: near the end of the function, after cross‑validation models produce final probabilities and just before the MBR features and final write‑back.","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Current code (abridged, as present in this branch):","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"# Determine which precursors failed the q-value cutoff prior to MBR\nqvals_prev = Vector{Float32}(undef, length(nonMBR_estimates))\nget_qvalues!(nonMBR_estimates, psms.target, qvals_prev)\npass_mask = (nonMBR_estimates .<= max_q_value_lightgbm_rescore)\nprob_thresh = any(pass_mask) ? minimum(nonMBR_estimates[pass_mask]) : typemax(Float32)\n\n# Label as transfer candidates only those failing the q-value cutoff but\n# whose best matched pair surpassed the passing probability threshold.\npsms[!, :MBR_transfer_candidate] .= .!pass_mask .&\n                                    (psms.MBR_max_pair_prob .>= prob_thresh)\n\n# Use the final MBR probabilities for all precursors\npsms[!, :prob] = MBR_estimates","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Note: nonMBR_estimates are probabilities (higher=better). max_q_value_lightgbm_rescore is a q‑value threshold (≈0.01) — a different scale.","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"What’s Wrong (Scale Mismatch)","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"pass_mask = (nonMBR_estimates .<= max_q_value_lightgbm_rescore) compares probabilities to a q‑value threshold. Since true positives have large probabilities (e.g., 0.8, 0.9), the condition p ≤ 0.01 is almost never true.\nConsequence: pass_mask is mostly false; .!pass_mask becomes “almost everyone”.\nprob_thresh = minimum(nonMBR_estimates[pass_mask]) is taken over a tiny set (often empty). If any are present, they tend to be extremely small (≈0), so the condition MBR_max_pair_prob ≥ prob_thresh is trivially satisfied by most rows.\nNet effect: MBR_transfer_candidate is set to true for the vast majority of rows, which matches your observation:","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"FTR probability threshold: 0.8703515\nNum passing candidate transfers: 1811822 out of 1949436","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"This happens because the candidate set (where MBR_transfer_candidate=true) includes almost every row, forcing the FTR threshold τ high to keep the empirical ratio below α.","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Correct Intent (Reference Implementation)","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"The out‑of‑memory path uses the correct logic inside update_mbr_probs! (same file):","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"function update_mbr_probs!(df::AbstractDataFrame, probs::AbstractVector{Float32}, qval_thresh::Float32)\n    prev_qvals = similar(df.prob)\n    get_qvalues!(df.prob, df.target, prev_qvals)   # compute q-values\n    pass_mask = (prev_qvals .<= qval_thresh) .& df.target\n    prob_thresh = any(pass_mask) ? minimum(df.prob[pass_mask]) : typemax(Float32)\n    df[!, :MBR_transfer_candidate] = (prev_qvals .> qval_thresh) .&   # use q-values\n                                     (df.MBR_max_pair_prob .>= prob_thresh)\n    df[!, :prob] = probs\n    return df\nend","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Two key differences from the in‑memory code above:\npass_mask is computed with q‑values prev_qvals, not with probabilities.\nprob_thresh is derived from the probabilities of the passing set (as intended), but the passing set is defined by qval_thresh, not a probability threshold.","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Impact of the Bug","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Candidate set is massively inflated in the in‑memory path, causing:\nVery high τ even at α = 0.01.\nLarge number of “candidate transfers” reported, which is misleading and slows down filtering.\nDownstream clamping affects almost all rows, reducing the discriminative power of MBR.","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Minimal Fix (In‑Memory Path)","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Replace the probability‑based pass_mask with a q‑value‑based mask (as in update_mbr_probs!). Proposed snippet drop‑in for sort_of_percolator_in_memory!:","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"# 1) Compute q-values of non-MBR predictions\nqvals_prev = Vector{Float32}(undef, length(nonMBR_estimates))\nget_qvalues!(nonMBR_estimates, psms.target, qvals_prev)\n\n# 2) Build pass/fail by q-value threshold\npass_mask = (qvals_prev .<= max_q_value_lightgbm_rescore) .& psms.target\nprob_thresh = any(pass_mask) ? minimum(nonMBR_estimates[pass_mask]) : typemax(Float32)\n\n# 3) Label transfer candidates: failed q-value but paired to a strong donor\npsms[!, :MBR_transfer_candidate] .= (qvals_prev .> max_q_value_lightgbm_rescore) .&\n                                    (psms.MBR_max_pair_prob .>= prob_thresh)","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"This aligns the in‑memory behavior with the out‑of‑memory update_mbr_probs! and ensures the candidate set is limited to plausible transfers.","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Verification Steps","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Add a short diagnostic around labeling (in‑memory):\nCount of pass_mask, candidate_count = sum(MBR_transfer_candidate), and prob_thresh.\nSanity: candidatecount should be a minority of all rows; `probthresh` should be a realistic boundary (e.g., near the minimum probability among passing targets).","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"Summary","category":"page"},{"location":"advanced/mbr_in_memory_candidate_labeling/","page":"-","title":"-","text":"The in‑memory path mistakenly compares probabilities to a q‑value threshold, inflating MBR_transfer_candidate.\nThe out‑of‑memory path uses the correct q‑value based mask.\nSwitching the in‑memory logic to use q‑values (as shown above) restores consistency and reduces the candidate set, leading to reasonable τ at α=0.01.","category":"page"},{"location":"#Introduction","page":"Home","title":"Introduction","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pioneer and its companion tool Altimeter are an open-source and performant solution for analysis of protein MS data acquired by data-independent acquisition (DIA). Poineer includes routines for searching DIA experments from Thermo and Sciex instruments and for building spectral libraries using the Koina interface. Given a spectral library of precursor fragment ion intensities and retention time estimates, Pioneer identifies and quantifies peptides from the library in the data.","category":"page"},{"location":"#Key-Features","page":"Home","title":"Key Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Isotope-Aware DIA Analysis: Narrow isolation windows distort fragment ion isotope distributions because the quadrupole partially transmits precursor isotopic envelopes. Pioneer addresses this by estimating a quadrupole transmission efficiency function for each scan and re-isotoping library spectra accordingly, using methods from Goldfarb et al.. This correction is critical for accurate matching and quantification in narrow-window DIA.\nAltimeter: Collision Energy-Independent Spectral Libraries: Altimeter predicts coefficients for B-splines that model total rather than monoisotopic fragment ion intensities as a function of normalized collision energy (NCE). Evaluating the splines at a given NCE produces a complete spectrum, so a single library works across different instruments and acquisition settings. Pioneer calibrates the optimal NCE per data file automatically.\nIntensity-Aware Fragment Index: Pioneer implements a fast fragment index search inspired by MSFragger and Sage. Pioneer's implementation uniquely leverages accurate fragment intensity predictions from in silico libraries—indexing only the highest-ranked fragments—to improve both speed and specificity of candidate identification.\nSpectral Deconvolution with Robust Regression: Pioneer explains each observed mass spectrum as a linear combination of template spectra from the library. To reduce quantitative bias from interfering signals in chimeric spectra, Pioneer minimizes the pseudo-Huber loss rather than squared error. For other examples of linear regression applied to DIA analyses, see Specter and Chimerys.\nDual-Window Quantification: In narrow-window DIA, a precursor's isotopic envelope is split across adjacent windows. Pioneer normalizes quantification by the isolated precursor fraction and combines signal from adjacent windows for denser chromatographic sampling and improved quantitative accuracy.\nMatch Between Runs: Pioneer transfers peptide identifications across runs with false transfer rate (FTR) control, increasing coverage in large-scale experiments.\nSpectral Library Prediction via Koina: Using Koina, Pioneer constructs fully predicted spectral libraries from a FASTA file and an internet connection. Pioneer uses Chronologer for retention time prediction and Altimeter for fragment ion intensity prediction.","category":"page"},{"location":"#Performance","page":"Home","title":"Performance","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Speed: 2–6x faster than DIA-NN and AlphaDIA on benchmark datasets\nFDR Control: Conservative false discovery rate control validated by entrapment analysis\nScalability: Memory consumption remains constant as the number of raw files grows, scaling to experiments with hundreds of runs","category":"page"},{"location":"#Current-Limitations","page":"Home","title":"Current Limitations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Variable modifications: Only oxidation of methionine (Unimod:35) is currently supported as a variable PTM\nDigestion: Fully enzymatic digestion only (no semi-enzymatic or non-specific searches)\nInterface: Command-line only; no graphical user interface yet","category":"page"},{"location":"#Quick-Links","page":"Home","title":"Quick Links","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Installation Guide\nQuick Start Tutorial","category":"page"},{"location":"#Authors-and-Development","page":"Home","title":"Authors and Development","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pioneer is developed and maintained by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Nathan Wamsley (Major Lab/Goldfarb Lab, Washington University)\nDennis Goldfarb (Goldfarb Lab, Washington University)","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you use Pioneer or Altimeter in your research, please cite:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Wamsley, N. T., Wilkerson, E. M., Major, M., & Goldfarb, D. \"Pioneer and Altimeter: Fast Analysis of DIA Proteomics Data Optimized for Narrow Isolation Windows.\" bioRxiv (2025). DOI: [forthcoming]","category":"page"},{"location":"#Contact","page":"Home","title":"Contact","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"For questions about Pioneer or to collaborate, please contact:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Nathan Wamsley (wamsleynathan@gmail.com)\nDennis Goldfarb (dennis.goldfarb@wustl.edu)","category":"page"},{"location":"","page":"Home","title":"Home","text":"For troubleshooting use the Issues page on GitHub. To critique methods or propose features use the Discussions page.","category":"page"},{"location":"#Exported-Methods","page":"Home","title":"Exported Methods","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Pioneer.SearchDIA","page":"Home","title":"Pioneer.SearchDIA","text":"SearchDIA(params_path::String)\n\nMain entry point for the DIA (Data-Independent Acquisition) search workflow. Executes a series of SearchMethods and generates performance metrics.\n\nParameters:\n\nparams_path: Path to JSON configuration file containing search parameters\n\nOutput:\n\nGenerates a log file in the results directory\nLong and wide-formatted tables (.arrow and .csv) for protein-group and precursor level id's and quantitation.\nReports timing and memory usage statistics\n\nExample:\n\njulia> SearchDIA(\"/path/to/config.json\")\n==========================================================================================\nSarting SearchDIA\n==========================================================================================\n\nStarting search at: 2024-12-30T14:01:01.510\nOutput directory: ./../data/ecoli_test/ecoli_test_results\n[ Info: Loading Parameters...\n[ Info: Loading Spectral Library...\n .\n .\n .\n\nIf it does not already exist, SearchDIA creates the user-specified results_dir and generates quality control plots, data tables, and logs.\n\nresults_dir/\n├── pioneer_search_log.txt\n├── qc_plots/\n│   ├── collision_energy_alignment/\n│   │   └── nce_alignment_plots.pdf\n│   ├── quad_transmission_model/\n│   │   ├── quad_data\n│   │   │   └── quad_data_plots.pdf\n│   │   └── quad_models\n│   │       └── quad_model_plots.pdf\n│   ├── rt_alignment_plots/\n│   │   └── rt_alignment_plots.pdf\n│   ├── mass_error_plots/\n│   │   └── mass_error_plots.pdf\n│   └── QC_PLOTS.pdf\n├── precursors_long.arrow\n├── precursors_long.tsv\n├── precursors_wide.arrow\n├── precurosrs_wide.tsv\n├── protein_groups_long.arrow\n├── protein_groups_long.tsv\n├── protein_groups_wide.arrow\n└── protein_groups_wide.tsv\n\n\n\n\n\n","category":"function"},{"location":"#Pioneer.GetSearchParams","page":"Home","title":"Pioneer.GetSearchParams","text":"GetSearchParams(lib_path::String, ms_data_path::String, results_path::String; \n               params_path::Union{String, Missing} = missing,\n               simplified::Bool = true)\n\nCreates a search parameter configuration file with user-specified paths.\n\nThe function loads default parameters from either the simplified or full JSON template (from assets/example_config/) and creates a customized parameter file with the user's file paths. All other parameters retain their default values and can be modified later.\n\nArguments:\n\nlib_path: Path to the spectral library file (.poin)\nmsdatapath: Path to the MS data directory  \nresults_path: Path where search results will be stored\nparamspath: Output path for the parameter file. Can be a directory (creates searchparameters.json)  or full file path. Defaults to \"search_parameters.json\" in current directory.\nsimplified: If true (default), uses simplified template with essential parameters only.  If false, uses full template with all advanced options.\n\nReturns:\n\nString: Path to the newly created search parameters file\n\nTemplates used:\n\nSimplified: defaultSearchParamsSimplified.json (basic parameters)\nFull: defaultSearchParams.json (all advanced parameters)\n\nExample:\n\n# Create simplified parameter file\noutput_path = GetSearchParams(\n    \"/path/to/speclib.poin\",\n    \"/path/to/ms/data/dir\", \n    \"/path/to/results/dir\"\n)\n\n# Create full parameter file with custom output location\noutput_path = GetSearchParams(\n    \"/path/to/speclib.poin\",\n    \"/path/to/ms/data/dir\",\n    \"/path/to/results/dir\";\n    params_path = \"/custom/path/my_params.json\",\n    simplified = false\n)\n\n\n\n\n\n","category":"function"},{"location":"#Pioneer.BuildSpecLib","page":"Home","title":"Pioneer.BuildSpecLib","text":"BuildSpecLib(params_path::String)\n\nMain function to build a spectral library from parameters. Executes a series of steps:\n\nParameter validation and directory setup\nFragment bound detection\nRetention time prediction (optional)\nFragment prediction (optional)\nLibrary index building\n\nParameters:\n\nparams_path: Path to JSON configuration file containing library building parameters\n\nOutput:\n\nGenerates a spectral library in the specified output directory\nCreates a detailed log file with timing and performance metrics\nReturns nothing\n\n\n\n\n\n","category":"function"},{"location":"#Pioneer.GetBuildLibParams","page":"Home","title":"Pioneer.GetBuildLibParams","text":"GetBuildLibParams(out_dir::String, lib_name::String, fasta_inputs; \n                 params_path::Union{String, Missing} = missing,\n                 regex_codes::Union{Missing, Dict, Vector} = missing,\n                 simplified::Bool = true)\n\nCreates a library building parameter configuration file with user-specified paths and FASTA files.\n\nThe function loads default parameters from either the simplified or full JSON template  (from assets/example_config/) and creates a customized parameter file with the user's paths and automatically discovered FASTA files. All other parameters retain their default values and can be modified later.\n\nArguments:\n\nout_dir: Output directory path where the library will be built\nlib_name: Name for the spectral library (used for directory and file naming)\nfasta_inputs: FASTA file specification. Can be:\nA single directory path (String) - searches for .fasta/.fasta.gz files\nA single FASTA file path (String) \nAn array of directories and/or FASTA file paths\nparamspath: Output path for the parameter file. Can be a directory (creates buildspeclibparams.json) or full file path. Defaults to \"buildspeclib_params.json\" in current directory.\nregex_codes: Optional FASTA header regex patterns for protein annotation extraction. Can be:\nA single Dict with keys: \"accessions\", \"genes\", \"proteins\", \"organisms\" (applied to all FASTA files)\nA Vector of Dicts for positional mapping to fasta_inputs\nIf missing, uses default patterns from the template\nsimplified: If true (default), uses simplified template with essential parameters only. If false, uses full template with all advanced library building options.\n\nReturns:\n\nString: Path to the newly created library building parameters file\n\nTemplates used:\n\nSimplified: defaultBuildLibParamsSimplified.json (basic parameters)\nFull: defaultBuildLibParams.json (all advanced parameters)\n\nThe function automatically:\n\nDiscovers FASTA files in specified directories\nGenerates appropriate library names from FASTA filenames\nExpands regex patterns to match the number of FASTA files found\nValidates that all specified paths exist and are accessible\n\nExample:\n\n# Create simplified parameter file with directory of FASTA files\noutput_path = GetBuildLibParams(\n    \"/path/to/output\", \n    \"my_library\",\n    \"/path/to/fasta/directory\"\n)\n\n# Create full parameter file with specific FASTA files and custom regex\noutput_path = GetBuildLibParams(\n    \"/path/to/output\",\n    \"my_library\", \n    [\"/path/to/human.fasta\", \"/path/to/yeast.fasta\"];\n    params_path = \"/custom/path/build_params.json\",\n    regex_codes = Dict(\"accessions\" => \"^sp\\|(\\w+)\\|\", \"genes\" => \" GN=(\\S+)\"),\n    simplified = false\n)\n\n\n\n\n\n","category":"function"},{"location":"#Pioneer.convertMzML","page":"Home","title":"Pioneer.convertMzML","text":"convertMzML(mzml_dir::String; skip_scan_header::Bool=true)\n\nConvert mzML mass spectrometry data files to Arrow IPC format.\n\nTakes either a directory containing mzML files or a path to a single mzML file and converts them to  Arrow format, preserving scan data including m/z arrays, intensity arrays, and scan metadata.\n\nArguments\n\nmzml_dir::String: Path to either a directory containing mzML files or a path to a single mzML file\nskip_scan_header::Bool=true: When true, omits scan header information from the output to reduce file size\n\nReturns\n\nnothing\n\nOutput\n\nCreates Arrow (.arrow) files in the same directory as the input mzML files and with the same base filename.\n\nExamples\n\n# Convert all mzML files in a directory\nconvertMzML(\"path/to/mzml/files\")\n\n# Convert a single mzML file\nconvertMzML(\"path/to/single/file.mzML\")\n\n# Include scan headers in output\nconvertMzML(\"path/to/mzml/files\", skip_scan_header=false)\n\nNotes\n\nEach mzML file is converted to a corresponding Arrow IPC (.arrow) file in the same directory. This is particularly useful for Sciex data where direct .wiff/.wiff2 conversion is not supported\n\n\n\n\n\n","category":"function"}]
}
